import streamlit as st  # å°å…¥Streamlitç”¨æ–¼å»ºç«‹Webæ‡‰ç”¨ç•Œé¢
from openai import OpenAI  # å°å…¥OpenAI APIå®¢æˆ¶ç«¯
import dotenv  # ç”¨æ–¼åŠ è¼‰ç’°å¢ƒè®Šé‡
import os
from PIL import Image  # ç”¨æ–¼åœ–åƒè™•ç†
from audio_recorder_streamlit import audio_recorder  # ç”¨æ–¼éŒ„éŸ³åŠŸèƒ½
import base64  # ç”¨æ–¼Base64ç·¨ç¢¼/è§£ç¢¼
from io import BytesIO  # ç”¨æ–¼è™•ç†äºŒé€²åˆ¶æ•¸æ“š
import random  # ç”¨æ–¼ç”Ÿæˆéš¨æ©Ÿæ•¸

# åŠ è¼‰ç’°å¢ƒè®Šé‡ï¼ˆæ¯”å¦‚APIå¯†é‘°ï¼‰
dotenv.load_dotenv()

# å®šç¾©å¯ç”¨çš„OpenAIæ¨¡å‹åˆ—è¡¨
openai_models = [
    "gpt-4o", 
    "gpt-4-turbo", 
    "gpt-3.5-turbo-16k", 
    "gpt-4", 
    "gpt-4-32k",
]

# ç”¨æ–¼æŸ¥è©¢å’Œä¸²æµLLMï¼ˆå¤§å‹èªè¨€æ¨¡å‹ï¼‰å›æ‡‰çš„å‡½æ•¸
def stream_llm_response(model_params, model_type="openai", api_key=None):
    response_message = ""

    if model_type == "openai":
        client = OpenAI(api_key=api_key)  # å‰µå»ºOpenAIå®¢æˆ¶ç«¯å¯¦ä¾‹
        # ä½¿ç”¨ä¸²æµæ¨¡å¼ç²å–AIå›æ‡‰
        for chunk in client.chat.completions.create(
            model=model_params["model"] if "model" in model_params else "gpt-4o",
            messages=st.session_state.messages,
            temperature=model_params["temperature"] if "temperature" in model_params else 0.3,
            max_tokens=4096,
            stream=True,
        ):
            chunk_text = chunk.choices[0].delta.content or ""
            response_message += chunk_text
            yield chunk_text

# å°‡åœ–åƒè½‰æ›ç‚ºBase64ç·¨ç¢¼çš„å‡½æ•¸
def get_image_base64(image_raw):
    buffered = BytesIO()
    image_raw.save(buffered, format=image_raw.format)
    img_byte = buffered.getvalue()
    return base64.b64encode(img_byte).decode('utf-8')

# å°‡æ–‡ä»¶è½‰æ›ç‚ºBase64ç·¨ç¢¼çš„å‡½æ•¸
def file_to_base64(file):
    with open(file, "rb") as f:
        return base64.b64encode(f.read())

# å°‡Base64ç·¨ç¢¼è½‰æ›å›åœ–åƒçš„å‡½æ•¸
def base64_to_image(base64_string):
    base64_string = base64_string.split(",")[1]
    return Image.open(BytesIO(base64.b64decode(base64_string)))

# ä¸»å‡½æ•¸
def main():
    # --- é é¢é…ç½® ---
    st.set_page_config(
        page_title="èŠå¤©æ©Ÿå™¨äºº",
        page_icon="ğŸ¤–",
        layout="centered",
        initial_sidebar_state="expanded",
    )

    # --- é é¢æ¨™é¡Œ ---
    st.html("""<h1 style="text-align: center; color: #6ca395;">ğŸ¤– <i>OpenaièŠå¤©æ©Ÿå™¨äºº</i> </h1>""")

    # --- å´é‚Šæ¬„è¨­ç½® ---
    with st.sidebar:
        cols_keys = st.columns(2)
        with cols_keys[0]:
            # ç²å–é è¨­çš„OpenAI APIå¯†é‘°ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
            default_openai_api_key = os.getenv("OPENAI_API_KEY") if os.getenv("OPENAI_API_KEY") is not None else ""
            with st.popover("ğŸ” APIå¯†é‘°"):
                openai_api_key = st.text_input("è«‹è¼¸å…¥æ‚¨çš„OpenAI APIå¯†é‘° (https://platform.openai.com/)", 
                                             value=default_openai_api_key, 
                                             type="password")

    # --- ä¸»è¦å…§å®¹ ---
    # æª¢æŸ¥ç”¨æˆ¶æ˜¯å¦è¼¸å…¥äº†APIå¯†é‘°
    if (openai_api_key == "" or openai_api_key is None or "sk-" not in openai_api_key):
        st.write("#")
        st.warning("â¬…ï¸ è«‹è¼¸å…¥APIå¯†é‘°ä»¥ç¹¼çºŒ...")
    
    else:
        client = OpenAI(api_key=openai_api_key)  # å‰µå»ºOpenAIå®¢æˆ¶ç«¯

        # åˆå§‹åŒ–èŠå¤©è¨˜éŒ„
        if "messages" not in st.session_state:
            st.session_state.messages = []

        # é¡¯ç¤ºä¹‹å‰çš„èŠå¤©è¨˜éŒ„
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                for content in message["content"]:
                    if content["type"] == "text":
                        st.write(content["text"])
                    elif content["type"] == "image_url":      
                        st.image(content["image_url"]["url"])
                    elif content["type"] == "video_file":
                        st.video(content["video_file"])
                    elif content["type"] == "audio_file":
                        st.audio(content["audio_file"])

        # --- å´é‚Šæ¬„æ¨¡å‹é¸é …å’Œè¼¸å…¥ ---
        with st.sidebar:
            st.divider()
            
            # é¡¯ç¤ºå¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
            available_models = [] + (openai_models if openai_api_key else [])
            model = st.selectbox("é¸æ“‡æ¨¡å‹:", available_models, index=0)
            model_type = None
            if model.startswith("gpt"): model_type = "openai"
            
            # æ¨¡å‹åƒæ•¸è¨­ç½®
            with st.popover("âš™ï¸ æ¨¡å‹åƒæ•¸"):
                model_temp = st.slider("æº«åº¦", min_value=0.0, max_value=2.0, value=0.3, step=0.1)

            # éŸ³é »å›æ‡‰é¸é …
            audio_response = st.toggle("éŸ³é »å›æ‡‰", value=False)
            if audio_response:
                cols = st.columns(2)
                with cols[0]:
                    tts_voice = st.selectbox("é¸æ“‡èªéŸ³:", 
                                           ["alloy", "echo", "fable", "onyx", "nova", "shimmer"])
                with cols[1]:
                    tts_model = st.selectbox("é¸æ“‡æ¨¡å‹:", ["tts-1", "tts-1-hd"], index=1)

            # è¨­ç½®æ¨¡å‹åƒæ•¸
            model_params = {
                "model": model,
                "temperature": model_temp,
            }

            # é‡ç½®å°è©±åŠŸèƒ½
            def reset_conversation():
                if "messages" in st.session_state and len(st.session_state.messages) > 0:
                    st.session_state.pop("messages", None)

            st.button("ğŸ—‘ï¸", on_click=reset_conversation)

            st.divider()

            # --- åœ–åƒä¸Šå‚³åŠŸèƒ½ ---
            if model in ["gpt-4o", "gpt-4-turbo"]:
                st.write(f"### **ä¸Šå‚³åœ–åƒ{' æˆ–å½±ç‰‡' if model_type=='google' else ''}:**")

                # æ·»åŠ åœ–åƒåˆ°è¨Šæ¯åˆ—è¡¨çš„å‡½æ•¸
                def add_image_to_messages():
                    if st.session_state.uploaded_img or ("camera_img" in st.session_state and st.session_state.camera_img):
                        img_type = st.session_state.uploaded_img.type if st.session_state.uploaded_img else "image/jpeg"
                        if img_type == "video/mp4":
                            # ä¿å­˜è¦–é »æ–‡ä»¶
                            video_id = random.randint(100000, 999999)
                            with open(f"video_{video_id}.mp4", "wb") as f:
                                f.write(st.session_state.uploaded_img.read())
                            st.session_state.messages.append(
                                {
                                    "role": "user", 
                                    "content": [{
                                        "type": "video_file",
                                        "video_file": f"video_{video_id}.mp4",
                                    }]
                                }
                            )
                        else:
                            # è™•ç†åœ–åƒæ–‡ä»¶
                            raw_img = Image.open(st.session_state.uploaded_img or st.session_state.camera_img)
                            img = get_image_base64(raw_img)
                            st.session_state.messages.append(
                                {
                                    "role": "user", 
                                    "content": [{
                                        "type": "image_url",
                                        "image_url": {"url": f"data:{img_type};base64,{img}"}
                                    }]
                                }
                            )

                # åœ–åƒä¸Šå‚³ä»‹é¢
                cols_img = st.columns(2)
                with cols_img[0]:
                    with st.popover("ğŸ“ ä¸Šå‚³"):
                        st.file_uploader(
                            f"ä¸Šå‚³åœ–åƒ{' æˆ–å½±ç‰‡' if model_type == 'google' else ''}:", 
                            type=["png", "jpg", "jpeg"] + (["mp4"] if model_type == "google" else []), 
                            accept_multiple_files=False,
                            key="uploaded_img",
                            on_change=add_image_to_messages,
                        )

                with cols_img[1]:                    
                    with st.popover("ğŸ“¸ æ‹ç…§"):
                        activate_camera = st.checkbox("å•Ÿå‹•ç›¸æ©Ÿ")
                        if activate_camera:
                            st.camera_input(
                                "æ‹å¼µç…§ç‰‡", 
                                key="camera_img",
                                on_change=add_image_to_messages,
                            )

            # --- éŸ³é »ä¸Šå‚³åŠŸèƒ½ ---
            st.write("#")
            st.write(f"### **ğŸ¤{' èªéŸ³è½‰æ–‡å­—' if model_type == 'openai' else ''}:**")

            # éŸ³é »è™•ç†ç›¸é—œè®Šé‡åˆå§‹åŒ–
            audio_prompt = None
            audio_file_added = False
            if "prev_speech_hash" not in st.session_state:
                st.session_state.prev_speech_hash = None

            # éŸ³é »éŒ„è£½ä»‹é¢
            speech_input = audio_recorder("æŒ‰ä½èªªè©±:", icon_size="3x", neutral_color="#6ca395")
            if speech_input and st.session_state.prev_speech_hash != hash(speech_input):
                st.session_state.prev_speech_hash = hash(speech_input)
                if model_type != "google":
                    # ä½¿ç”¨OpenAIçš„Whisperæ¨¡å‹é€²è¡ŒèªéŸ³è½‰æ–‡å­—
                    transcript = client.audio.transcriptions.create(
                        model="whisper-1", 
                        file=("audio.wav", speech_input),
                    )
                    audio_prompt = transcript.text
                elif model_type == "google":
                    # ä¿å­˜éŸ³é »æ–‡ä»¶
                    audio_id = random.randint(100000, 999999)
                    with open(f"audio_{audio_id}.wav", "wb") as f:
                        f.write(speech_input)
                    st.session_state.messages.append(
                        {
                            "role": "user", 
                            "content": [{
                                "type": "audio_file",
                                "audio_file": f"audio_{audio_id}.wav",
                            }]
                        }
                    )
                    audio_file_added = True

        # --- èŠå¤©è¼¸å…¥è™•ç† ---
        if prompt := st.chat_input("å—¨ï¼å•æˆ‘ä»»ä½•å•é¡Œ...") or audio_prompt or audio_file_added:
            if not audio_file_added:
                # æ·»åŠ æ–‡æœ¬è¨Šæ¯
                st.session_state.messages.append(
                    {
                        "role": "user", 
                        "content": [{
                            "type": "text",
                            "text": prompt or audio_prompt,
                        }]
                    }
                )
                
                # é¡¯ç¤ºæ–°è¨Šæ¯
                with st.chat_message("user"):
                    st.markdown(prompt)
            else:
                # é¡¯ç¤ºéŸ³é »æ–‡ä»¶
                with st.chat_message("user"):
                    st.audio(f"audio_{audio_id}.wav")

            # é¡¯ç¤ºAIåŠ©æ‰‹å›æ‡‰
            with st.chat_message("assistant"):
                model2key = {
                    "openai": openai_api_key,
                }
                st.write_stream(
                    stream_llm_response(
                        model_params=model_params, 
                        model_type=model_type, 
                        api_key=model2key[model_type]
                    )
                )

            # --- æ·»åŠ éŸ³é »å›æ‡‰ï¼ˆå¯é¸ï¼‰ ---
            if audio_response:
                # ä½¿ç”¨OpenAIçš„TTSæœå‹™ç”ŸæˆèªéŸ³å›æ‡‰
                response = client.audio.speech.create(
                    model=tts_model,
                    voice=tts_voice,
                    input=st.session_state.messages[-1]["content"][0]["text"],
                )
                audio_base64 = base64.b64encode(response.content).decode('utf-8')
                # å‰µå»ºéŸ³é »æ’­æ”¾å™¨
                audio_html = f"""
                <audio controls autoplay>
                    <source src="data:audio/wav;base64,{audio_base64}" type="audio/mp3">
                </audio>
                """
                st.html(audio_html)

# ç¨‹å¼å…¥å£é»
if __name__=="__main__":
    main()
