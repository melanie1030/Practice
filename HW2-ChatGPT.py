import streamlit as st
from openai import OpenAI
import dotenv
import os
from PIL import Image
from audio_recorder_streamlit import audio_recorder
import base64
from io import BytesIO
import random

# --- åˆå§‹åŒ–èˆ‡è¨­ç½® ---
dotenv.load_dotenv()

# å®šç¾©å…¨åŸŸè®Šæ•¸
OPENAI_MODELS = ["gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo-16k", "gpt-4", "gpt-4-32k"]

# --- è¼”åŠ©å‡½æ•¸ ---

def initialize_client(api_key):
    """Initialize OpenAI client with the provided API key."""
    return OpenAI(api_key=api_key) if api_key else None

def load_image_base64(image):
    """Convert an image to Base64 encoding."""
    buffer = BytesIO()
    image.save(buffer, format=image.format)
    return base64.b64encode(buffer.getvalue()).decode('utf-8')

def add_user_image(image):
    """Add an image message to the session state."""
    img_base64 = load_image_base64(image)
    st.session_state.messages.append({
        "role": "user",
        "content": [{"type": "image_url", "image_url": {"url": f"data:image/png;base64,{img_base64}"}}]
    })

def reset_session_messages():
    """Clear conversation history from the session."""
    if "messages" in st.session_state:
        st.session_state.pop("messages")

# --- Chatbot Main Functionality ---

def stream_llm_response(client, model_params):
    """Stream responses from the LLM model."""
    for chunk in client.chat.completions.create(
            model=model_params.get("model", "gpt-4o"),
            messages=st.session_state.messages,
            temperature=model_params.get("temperature", 0.3),
            max_tokens=4096,
            stream=True):
        chunk_text = chunk.choices[0].delta.content or ""
        yield chunk_text

def main():
    # --- é é¢é…ç½® ---
    st.set_page_config(page_title="èŠå¤©æ©Ÿå™¨äºº", page_icon="ğŸ¤–", layout="centered", initial_sidebar_state="expanded")
    st.html("""<h1 style="text-align: center; color: #6ca395;">ğŸ¤– <i>OpenAI èŠå¤©æ©Ÿå™¨äºº</i> </h1>""")

    # --- å´é‚Šæ¬„è¨­ç½® ---
    with st.sidebar:
        st.subheader("ğŸ” è¼¸å…¥æ‚¨çš„APIå¯†é‘°")
        default_api_key = os.getenv("OPENAI_API_KEY", "")
        api_key = st.text_input("OpenAI APIå¯†é‘°", value=default_api_key, type="password")

        client = initialize_client(api_key)
        if not api_key or not client:
            st.warning("â¬…ï¸ è«‹è¼¸å…¥APIå¯†é‘°ä»¥ç¹¼çºŒ...")
            return

        # æ¨¡å‹è¨­ç½®
        model = st.selectbox("é¸æ“‡æ¨¡å‹:", OPENAI_MODELS)
        model_params = {"model": model, "temperature": st.slider("æº«åº¦", 0.0, 2.0, 0.3)}

        # é‡ç½®å°è©±
        st.button("ğŸ—‘ï¸ æ¸…é™¤å°è©±", on_click=reset_session_messages)

    # --- èŠå¤©çª—å£èˆ‡è¨Šæ¯ ---
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            for content in message["content"]:
                if content["type"] == "text":
                    st.write(content.get("text", ""))
                elif content["type"] == "image_url":
                    st.image(content["image_url"].get("url", ""))

    # --- åœ–åƒä¸Šå‚³åŠŸèƒ½ ---
    st.write("### ä¸Šå‚³åœ–åƒæˆ–æ‹ç…§")
    cols_img = st.columns(2)
    
    # åœ–åƒä¸Šå‚³
    with cols_img[0]:
        uploaded_img = st.file_uploader("é¸æ“‡ä¸€å¼µåœ–ç‰‡:", type=["png", "jpg", "jpeg"])
        if uploaded_img:
            img = Image.open(uploaded_img)
            add_user_image(img)
            st.success("åœ–åƒå·²ä¸Šå‚³!")

    # ç›¸æ©Ÿæ‹ç…§
    with cols_img[1]:
        camera_img = st.camera_input("æ‹ç…§")
        if camera_img:
            img = Image.open(camera_img)
            add_user_image(img)
            st.success("æ‹ç…§å·²æˆåŠŸ!")

    # --- ç”¨æˆ¶è¼¸å…¥ ---
    prompt = st.chat_input("å—¨ï¼å•æˆ‘ä»»ä½•å•é¡Œ...")
    if prompt:
        st.session_state.messages.append({
            "role": "user",
            "content": [{"type": "text", "text": prompt}]
        })
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            st.write_stream(stream_llm_response(client, model_params))

# ç¨‹å¼å…¥å£é»
if __name__ == "__main__":
    main()
