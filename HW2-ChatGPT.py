import openai
import streamlit as st
import pandas as pd

# ä½¿ç”¨æ‚¨çš„ OpenAI API é‡‘é‘°
OPENAI_API_KEY = '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'
openai.api_key = OPENAI_API_KEY

# Streamlit App æ¨™é¡Œ
st.title("ChatGPT Service æ‰“é€  ğŸ¤–")
st.subheader("æ‚¨å¥½!! æ­¡è¿æ‚¨å•æˆ‘ç­”~")

# åˆå§‹åŒ–å°è©±æ­·å²
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å¹«åŠ©äººçš„åŠ©ç†ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚"}
    ]

# HTML + CSS: è‡ªè¨‚èŠå¤©æ³¡æ³¡
def render_messages():
    with chat_placeholder.container():
        for message in st.session_state["messages"]:
            if message["role"] == "system":
                continue
            elif message["role"] == "user":
                st.markdown(f"""
                <div class="user-container">
                    <div class="user-bubble">
                        {message['content']}
                    </div>
                    <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh6XGT5Hz9MpAiyfTHlBczavuUjyTBza9zWdzYmoifglj0p1lsylcTEScnpSa-Youh7YXw-ssgO-mMQmw-DBz4NeesioQPTe8beOH_QS-A4JMnfZAGP-01gxPQrS-pPEnrnJxbdVnWguhCC/s1600/pose_pien_uruuru_woman.png" alt="User">
                </div>
                """, unsafe_allow_html=True)
            elif message["role"] == "assistant":
                st.markdown(f"""
                <div class="ai-container">
                    <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjCHBgyqLrwRdbSM72R9PutXIqxbI9yR5UzXWC0TYIYVlKgHH5TzkaHijRkdxQMRSJx8upcecs2RGHYW7gVOSQPH-LUrPUg3esbqx5-7Q04BPJWD-DdzTealzGBQehfXpDeLxYe29MjQQgo/s1600/megane_hikaru_woman.png" alt="AI">
                    <div class="ai-bubble">
                        {message['content']}
                    </div>
                </div>
                """, unsafe_allow_html=True)

# é¡¯ç¤ºèŠå¤©æ­·å²
chat_placeholder = st.empty()
render_messages()

# ä¸Šå‚³æª”æ¡ˆå€åŸŸ
uploaded_file = st.file_uploader("ä¸Šå‚³æª”æ¡ˆ", type=["csv", "xlsx", "txt", "pdf", "jpg", "png", "jpeg"])

# è™•ç†ä¸Šå‚³æª”æ¡ˆ
if uploaded_file:
    try:
        if uploaded_file.name.endswith(".csv"):
            df = pd.read_csv(uploaded_file)
            st.session_state["messages"].append(
                {"role": "user", "content": f"å·²ä¸Šå‚³ CSV æª”æ¡ˆï¼š{uploaded_file.name}ï¼Œä»¥ä¸‹æ˜¯å…§å®¹ï¼š\n{df.to_string(index=False)}"}
            )
        elif uploaded_file.name.endswith(".xlsx"):
            df = pd.read_excel(uploaded_file)
            st.session_state["messages"].append(
                {"role": "user", "content": f"å·²ä¸Šå‚³ Excel æª”æ¡ˆï¼š{uploaded_file.name}ï¼Œä»¥ä¸‹æ˜¯å…§å®¹ï¼š\n{df.to_string(index=False)}"}
            )
        else:
            file_info = f"å·²ä¸Šå‚³æª”æ¡ˆï¼š{uploaded_file.name} (å¤§å°ï¼š{uploaded_file.size} bytes)"
            st.session_state["messages"].append({"role": "user", "content": file_info})
    except Exception as e:
        st.error(f"ç„¡æ³•è®€å–æª”æ¡ˆï¼š{e}")

    render_messages()

# ä½¿ç”¨è€…è¼¸å…¥å€åŸŸ
user_input = st.chat_input("è¼¸å…¥è¨Šæ¯ï¼š")

# è™•ç†ä½¿ç”¨è€…è¼¸å…¥ä¸¦å‘¼å« OpenAI API
if user_input:
    st.session_state["messages"].append({"role": "user", "content": user_input})
    render_messages()

    with st.spinner("AI æ­£åœ¨å›æ‡‰..."):
        try:
            # å‘¼å« OpenAI API
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",  # å‘¼å«æ¨¡å‹
                messages=st.session_state["messages"]
            )

            # å–å¾—å›æ‡‰å…§å®¹
            full_response = response.choices[0].message.content
            st.session_state["messages"].append({"role": "assistant", "content": full_response})

            # é¡¯ç¤º AI å›æ‡‰
            with st.chat_message("assistant"):
                st.markdown(full_response)

        except Exception as e:
            st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    render_messages()
