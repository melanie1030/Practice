import streamlit as st
import pandas as pd
from openai import OpenAI

# åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯
OPENAI_API_KEY = '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'
client = OpenAI(api_key=OPENAI_API_KEY)

# Streamlit æ¨™é¡Œå’Œå‰¯æ¨™é¡Œ
st.title("ChatGPT Service æ‰“é€  ğŸ¤–")
st.subheader("æ‚¨å¥½!! æ­¡è¿æ‚¨å•æˆ‘ç­”~")

# åˆå§‹åŒ–èŠå¤©è¨˜éŒ„
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å¹«åŠ©äººçš„åŠ©ç†ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚"}
    ]

# æ¸²æŸ“è¨Šæ¯çš„å‡½æ•¸
def render_messages():
    with chat_placeholder.container():
        for message in st.session_state["messages"]:
            if message["role"] == "system":
                continue
            elif message["role"] == "user":
                st.markdown(f"""
                <div class="user-container">
                    <div class="user-bubble">
                        {message['content']}
                    </div>
                    <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh6XGT5Hz9MpAiyfTHlBczavuUjyTBza9zWdzYmoifglj0p1lsylcTEScnpSa-Youh7YXw-ssgO-mMQmw-DBz4NeesioQPTe8beOH_QS-A4JMnfZAGP-01gxPQrS-pPEnrnJxbdVnWguhCC/s1600/pose_pien_uruuru_woman.png" alt="User">
                </div>
                """, unsafe_allow_html=True)
            elif message["role"] == "assistant":
                st.markdown(f"""
                <div class="ai-container">
                    <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjCHBgyqLrwRdbSM72R9PutXIqxbI9yR5UzXWC0TYIYVlKgHH5TzkaHijRkdxQMRSJx8upcecs2RGHYW7gVOSQPH-LUrPUg3esbqx5-7Q04BPJWD-DdzTealzGBQehfXpDeLxYe29MjQQgo/s1600/megane_hikaru_woman.png" alt="AI">
                    <div class="ai-bubble">
                        {message['content']}
                    </div>
                </div>
                """, unsafe_allow_html=True)

# èŠå¤©è¨Šæ¯çš„å ä½ç¬¦
chat_placeholder = st.empty()
render_messages()

# ä¸Šå‚³æª”æ¡ˆå€å¡Š
uploaded_file = st.file_uploader("ä¸Šå‚³æª”æ¡ˆ", type=["csv", "xlsx", "txt", "pdf", "jpg", "png", "jpeg"])

# æª”æ¡ˆè™•ç†é‚è¼¯
if uploaded_file:
    try:
        if uploaded_file.name.endswith(".csv"):
            df = pd.read_csv(uploaded_file)
            st.session_state["messages"].append(
                {"role": "user", "content": f"å·²ä¸Šå‚³ CSV æª”æ¡ˆï¼š{uploaded_file.name}ï¼Œä»¥ä¸‹æ˜¯å…§å®¹ï¼š\n{df.to_string(index=False)}"}
            )
        elif uploaded_file.name.endswith(".xlsx"):
            df = pd.read_excel(uploaded_file)
            st.session_state["messages"].append(
                {"role": "user", "content": f"å·²ä¸Šå‚³ Excel æª”æ¡ˆï¼š{uploaded_file.name}ï¼Œä»¥ä¸‹æ˜¯å…§å®¹ï¼š\n{df.to_string(index=False)}"}
            )
        else:
            file_info = f"å·²ä¸Šå‚³æª”æ¡ˆï¼š{uploaded_file.name} (å¤§å°ï¼š{uploaded_file.size} bytes)"
            st.session_state["messages"].append({"role": "user", "content": file_info})

    except Exception as e:
        st.error(f"ç„¡æ³•è®€å–æª”æ¡ˆï¼š{e}")

    render_messages()

# è¼¸å…¥å€åŸŸï¼ˆåœ¨æª”æ¡ˆä¸Šå‚³å€å¡Šä¸‹æ–¹ï¼‰
user_input = st.chat_input("è¼¸å…¥è¨Šæ¯ï¼š")

# ä½¿ç”¨è€…è¼¸å…¥çš„è™•ç†
if user_input:
    st.session_state["messages"].append({"role": "user", "content": user_input})
    render_messages()

    # å‘¼å« OpenAI API ç”Ÿæˆå›æ‡‰
    with st.spinner("AI æ­£åœ¨å›æ‡‰..."):
        try:
            response = client.chat.completions.create(
                model="gpt-4.0",  # æ”¹ç‚ºä½¿ç”¨ GPT-4.0 æ¨¡å‹
                messages=st.session_state["messages"]
            )
            answer = response.choices[0].message.content
            st.session_state["messages"].append({"role": "assistant", "content": answer})

        except Exception as e:
            st.error(f"API éŒ¯èª¤ï¼š{e}")

    render_messages()
