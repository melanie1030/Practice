import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import json
import traceback
import re
import os
import dotenv
import base64
import io
import requests
from PIL import Image
from streamlit_ace import st_ace

# --- Initialize and Settings ---
dotenv.load_dotenv()

UPLOAD_DIR = "uploaded_files"

OPENAI_MODELS = [
    "gpt-4o",  # å‡è¨­å¯è§£æåœ–ç‰‡çš„å¯¦é©—æ¨¡å‹
    "gpt-4-turbo",
    "gpt-3.5-turbo-16k",
    "gpt-4",
    "gpt-4-32k"
]

def debug_log(msg):
    if st.session_state.get("debug_mode", False):
        st.write(f"**DEBUG LOG:** {msg}")
        print(msg)

def debug_error(msg):
    if st.session_state.get("debug_mode", False):
        st.error(f"**DEBUG ERROR:** {msg}")
        print(msg)

def save_uploaded_file(uploaded_file):
    if not os.path.exists(UPLOAD_DIR):
        os.makedirs(UPLOAD_DIR)
    file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)

    debug_log(f"Saving file to {file_path}")
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    debug_log(f"Files in {UPLOAD_DIR}: {os.listdir(UPLOAD_DIR)}")
    return file_path

def add_user_image(img):
    """
    è™•ç†ä¸Šå‚³çš„åœ–ç‰‡ï¼š
    1. ä¿å­˜åœ–ç‰‡
    2. è½‰æ›ç‚º Base64
    3. å°‡åœ–ç‰‡åµŒå…¥åˆ°å°è©±è¨˜éŒ„ä¸­
    """
    try:
        # ä¿å­˜åœ–ç‰‡
        if not os.path.exists(UPLOAD_DIR):
            os.makedirs(UPLOAD_DIR)
        image_filename = f"user_image_{len(os.listdir(UPLOAD_DIR)) + 1}.png"
        image_path = os.path.join(UPLOAD_DIR, image_filename)
        img.save(image_path, format="PNG")
        debug_log(f"Image saved to {image_path}")

        # è½‰æ›ç‚º Base64
        buffered = io.BytesIO()
        img.save(buffered, format="PNG")
        img_bytes = buffered.getvalue()
        image_base64 = base64.b64encode(img_bytes).decode("utf-8")
        debug_log("Image has been converted to base64.")
        debug_log(f"Image base64 (first 100 chars): {image_base64[:100]}...")

        # å°‡åœ–ç‰‡åµŒå…¥åˆ°å°è©±è¨˜éŒ„ä¸­
        image_message = f"Here is the image you uploaded:\n![Uploaded Image](data:image/png;base64,{image_base64})"
        st.session_state.messages.append({"role": "user", "content": image_message})
        debug_log("Image data appended as a separate user message.")

        st.success("åœ–åƒå·²ä¸Šå‚³!")

    except Exception as e:
        if st.session_state.debug_mode:
            st.error(f"Error processing image: {e}")
        debug_log(f"Error processing image: {e}")

def execute_code(code, global_vars=None):
    try:
        exec_globals = global_vars if global_vars else {}
        debug_log("Ready to execute the following code:")
        if st.session_state.get("debug_mode", False):
            st.code(code, language="python")

        debug_log(f"Executing code with global_vars: {list(exec_globals.keys())}")
        exec(code, exec_globals)
        output = exec_globals.get("output", "(No output returned)")
        debug_log(f"Execution output: {output}")
        return f"Code executed successfully. Output: {output}"
    except Exception as e:
        error_msg = f"Error executing code:\n{traceback.format_exc()}"
        debug_log(f"Execution error: {error_msg}")
        if st.session_state.get("debug_mode", False):
            return error_msg
        else:
            return "Error executing code (hidden in non-debug mode)."

def extract_json_block(response: str) -> str:
    pattern = r'```(?:json)?\s*(.*?)\s*```'
    match = re.search(pattern, response, re.DOTALL)
    if match:
        json_str = match.group(1).strip()
        debug_log(f"Extracted JSON block: {json_str}")
        return json_str
    else:
        debug_log("No JSON block found in response.")
        return response.strip()

def stream_llm_response(api_key, model, messages, temperature=0.3, max_tokens=4096):
    """Stream responses from the LLM model."""
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    data = {
        "model": model,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "stream": True
    }
    debug_log(f"Sending API request to OpenAI with data: {json.dumps(data, ensure_ascii=False)}")
    response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=data, stream=True)
    
    debug_log(f"Received response with status code: {response.status_code}")
    if response.status_code != 200:
        error_content = response.text
        debug_error(f"OpenAI API returned an error: {response.status_code} - {error_content}")
        raise Exception(f"OpenAI API returned an error: {response.status_code} - {error_content}")
    
    response_content = ""
    assistant_placeholder = st.empty()  # Create a placeholder for assistant's response
    for line in response.iter_lines():
        if line:
            decoded_line = line.decode('utf-8')
            debug_log(f"Received line: {decoded_line}")
            if decoded_line.startswith("data: "):
                decoded_line = decoded_line.replace("data: ", "")
                if decoded_line == "[DONE]":
                    debug_log("Stream finished.")
                    break
                try:
                    chunk = json.loads(decoded_line)
                    chunk_text = chunk['choices'][0]['delta'].get('content', '')
                    debug_log(f"Chunk text: {chunk_text}")
                    response_content += chunk_text
                    # Update the assistant's response in the placeholder
                    assistant_placeholder.markdown(response_content)
                except json.JSONDecodeError as e:
                    debug_error(f"JSON decode error: {e}")
                    continue
    return response_content

def main():
    st.set_page_config(page_title="Chatbot + Data Analysis", page_icon="ğŸ¤–", layout="wide")
    st.title("ğŸ¤– Chatbot + ğŸ“Š Data Analysis + ğŸ§  Memory + ğŸ–‹ï¸ Canvas (With Debug & Deep Analysis)")

    # Initialize session state variables
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "ace_code" not in st.session_state:
        st.session_state.ace_code = ""
    if "editor_location" not in st.session_state:
        st.session_state.editor_location = "Main"
    if "uploaded_file_path" not in st.session_state:
        st.session_state.uploaded_file_path = None
    if "uploaded_image_path" not in st.session_state:
        st.session_state.uploaded_image_path = None
    if "image_base64" not in st.session_state:
        st.session_state.image_base64 = None
    if "debug_mode" not in st.session_state:
        st.session_state.debug_mode = False
    if "deep_analysis_mode" not in st.session_state:
        st.session_state.deep_analysis_mode = False
    if "second_response" not in st.session_state:
        st.session_state.second_response = ""
    if "third_response" not in st.session_state:
        st.session_state.third_response = ""
    if "deep_analysis_image" not in st.session_state:
        st.session_state.deep_analysis_image = None

    with st.sidebar:
        st.subheader("ğŸ”’ Enter Your API Key")
        api_key = st.text_input("OpenAI API Key", type="password")

        selected_model = st.selectbox("é¸æ“‡æ¨¡å‹:", OPENAI_MODELS, index=0)

        st.session_state.debug_mode = st.checkbox("Debug Mode", value=False)
        st.session_state.deep_analysis_mode = st.checkbox("æ·±åº¦åˆ†ææ¨¡å¼", value=False)

        if "memory" not in st.session_state:
            st.session_state.memory = []

        if "conversation_initialized" not in st.session_state:
            if api_key:
                st.session_state.conversation_initialized = True
                st.session_state.messages = []  # Initialize with empty message history
                debug_log("Conversation initialized with empty message history.")
            else:
                st.warning("â¬…ï¸ è«‹è¼¸å…¥ API Key ä»¥åˆå§‹åŒ–èŠå¤©æ©Ÿå™¨äººã€‚")

        if st.session_state.debug_mode:
            debug_log(f"Currently using model => {selected_model}")

        if st.button("ğŸ—‘ï¸ Clear Memory"):
            st.session_state.memory = []
            st.session_state.messages = []
            st.session_state.ace_code = ""
            st.session_state.uploaded_file_path = None
            st.session_state.uploaded_image_path = None
            st.session_state.image_base64 = None
            st.session_state.deep_analysis_mode = False
            st.session_state.second_response = ""
            st.session_state.third_response = ""
            st.session_state.deep_analysis_image = None
            st.success("Memory cleared!")
            debug_log("Memory has been cleared.")

        st.subheader("ğŸ§  Memory State")
        if st.session_state.messages:
            memory_content = "\n".join([f"{msg['role']}: {msg['content']}" for msg in st.session_state.messages])
            st.text_area("Current Memory", value=memory_content, height=200)
            debug_log(f"Current memory content: {memory_content}")
        else:
            st.text_area("Current Memory", value="No messages yet.", height=200)
            debug_log("No messages in memory.")

        # --- CSV ä¸Šå‚³ ---
        st.subheader("ğŸ“‚ Upload a CSV File")
        uploaded_file = st.file_uploader("Choose a CSV file:", type=["csv"])
        csv_data = None
        if uploaded_file:
            st.session_state.uploaded_file_path = save_uploaded_file(uploaded_file)
            debug_log(f"Uploaded file path: {st.session_state.uploaded_file_path}")
            try:
                csv_data = pd.read_csv(st.session_state.uploaded_file_path)
                st.write("### Data Preview")
                st.dataframe(csv_data)
                debug_log(f"CSV Data Columns: {list(csv_data.columns)}")
            except Exception as e:
                if st.session_state.debug_mode:
                    st.error(f"Error reading CSV: {e}")
                debug_log(f"Error reading CSV: {e}")

        # --- åœ–ç‰‡ä¸Šå‚³ ---
        st.subheader("ğŸ–¼ï¸ Upload an Image")
        uploaded_image = st.file_uploader("é¸æ“‡ä¸€å¼µåœ–ç‰‡:", type=["png", "jpg", "jpeg"])
        if uploaded_image:
            add_user_image(Image.open(uploaded_image))

        st.subheader("Editor Location")
        location = st.radio(
            "Choose where to display the editor:",
            ["Main", "Sidebar"],
            index=0 if st.session_state.editor_location == "Main" else 1
        )
        st.session_state.editor_location = location
        debug_log(f"Editor location set to: {st.session_state.editor_location}")

    # --- é¡¯ç¤ºæ­·å²è¨Šæ¯ ---
    for idx, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            if "content" in message:
                st.write(message["content"])
                st.write(st.session_satate)
                debug_log(f"Displaying message {idx} from {message['role']}: {message['content']}")
            if "code" in message:
                st.code(message["code"], language="python")
                debug_log(f"Displaying code from {message['role']}: {message['code']}")

    user_input = st.chat_input("Hi! Ask me anything...")
    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.write(user_input)
            debug_log(f"User input added to messages: {user_input}")

        with st.spinner("Thinking..."):
            try:
                debug_log(f"Uploaded file path: {st.session_state.uploaded_file_path}")
                debug_log(f"Uploaded image path: {st.session_state.uploaded_image_path}")

                # --- ç¢ºä¿ system prompt åƒ…æ·»åŠ ä¸€æ¬¡ ---
                if not any(msg["role"] == "system" for msg in st.session_state.messages):
                    system_prompt = "ä½ æ˜¯ä¸€å€‹å”åŠ©é€²è¡Œæ•¸æ“šåˆ†æçš„åŠ©æ‰‹ã€‚"
                    st.session_state.messages.insert(0, {"role": "system", "content": system_prompt})
                    debug_log("System prompt added to messages.")

                # --- æ±ºå®šä½¿ç”¨å“ªç¨® prompt ---
                if st.session_state.uploaded_image_path is not None and st.session_state.image_base64:
                    # åœ–ç‰‡å·²ä¸Šå‚³ï¼Œåœ–ç‰‡æ•¸æ“šå·²ä½œç‚ºå–®ç¨çš„è¨Šæ¯æ·»åŠ 
                    prompt = user_input  # ç›´æ¥ä½¿ç”¨ç”¨æˆ¶è¼¸å…¥
                    debug_log("User input with image data already appended.")
                else:
                    # æ²’æœ‰åœ–ç‰‡ä¸Šå‚³ï¼Œä½¿ç”¨è¤‡é›œçš„ JSON é‚è¼¯
                    if st.session_state.uploaded_file_path is not None:
                        try:
                            df_temp = pd.read_csv(st.session_state.uploaded_file_path)
                            csv_columns = ", ".join(df_temp.columns)
                            debug_log(f"CSV columns: {csv_columns}")
                        except Exception as e:
                            csv_columns = "ç„¡æ³•è®€å–æ¬„ä½"
                            if st.session_state.debug_mode:
                                st.error(f"Error reading columns: {e}")
                            debug_log(f"Error reading columns: {e}")
                    else:
                        csv_columns = "ç„¡ä¸Šå‚³æª”æ¡ˆ"
                        debug_log("No CSV file uploaded.")

                    if st.session_state.uploaded_file_path is not None and csv_columns != "ç„¡ä¸Šå‚³æª”æ¡ˆ":
                        prompt = f"""Please respond with a JSON object in the format:
{{
    "content": "é€™æ˜¯æˆ‘çš„è§€å¯Ÿï¼š{{{{åˆ†æå…§å®¹}}}}",
    "code": "import pandas as pd\\nimport streamlit as st\\nimport matplotlib.pyplot as plt\\n# è®€å– CSV æª”æ¡ˆ (è«‹ç›´æ¥ä½¿ç”¨ st.session_state.uploaded_file_path è®Šæ•¸)\\ndata = pd.read_csv(st.session_state.uploaded_file_path)\\n\\n# åœ¨é€™è£¡åŠ å…¥ä½ è¦çš„ç¹ªåœ–æˆ–åˆ†æé‚è¼¯\\n\\n# ä¾‹å¦‚ä½¿ç”¨ st.pyplot() ä¾†é¡¯ç¤ºåœ–è¡¨:\\n# fig, ax = plt.subplots()\\n# ax.scatter(data['colA'], data['colB'])\\n# st.pyplot(fig)\\n"
}}
Important:
1) Must use st.session_state.uploaded_file_path as the CSV path (instead of a hardcoded path)
2) Must use st.pyplot() to display any matplotlib figure
3) Return only valid JSON (escape any special characters if needed)

Based on the request: {user_input}.
Available columns: {csv_columns}.
"""
                        debug_log("Prompt constructed for CSV input with JSON response.")
                        st.session_state.messages.append({"role": "system", "content": prompt})
                        debug_log("System prompt appended to messages.")
                    else:
                        prompt = f"è«‹å…¨éƒ¨ä»¥ç¹é«”ä¸­æ–‡å›ç­”æ­¤å•é¡Œï¼š{user_input}"
                        debug_log("Prompt constructed for plain text input.")
                        st.session_state.messages.append({"role": "system", "content": prompt})
                        debug_log("Plain text system prompt appended to messages.")

                # Make the API request and stream the response
                response_content = stream_llm_response(api_key, selected_model, st.session_state.messages, temperature=0.5)
                debug_log(f"Full assistant response: {response_content}")

                # After streaming is done, append assistant message
                st.session_state.messages.append({"role": "assistant", "content": response_content})
                with st.chat_message("assistant"):
                    st.write(response_content)
                    debug_log(f"Assistant response added to messages: {response_content}")

                # Extract JSON and code
                json_str = extract_json_block(response_content)
                try:
                    response_json = json.loads(json_str)
                    debug_log("JSON parsing successful.")
                except Exception as e:
                    debug_log(f"json.loads parsing error: {e}")
                    debug_error(f"json.loads parsing error: {e}")
                    response_json = {"content": json_str, "code": ""}
                    debug_log("Fallback to raw response for content.")

                content = response_json.get("content", "é€™æ˜¯æˆ‘çš„åˆ†æï¼š")
                st.session_state.messages.append({"role": "assistant", "content": content})
                with st.chat_message("assistant"):
                    st.write(content)
                    debug_log(f"Content from JSON appended to messages: {content}")

                code = response_json.get("code", "")
                if code:
                    st.session_state.messages.append({"role": "assistant", "code": code})
                    with st.chat_message("assistant"):
                        st.code(code, language="python")
                        debug_log(f"Code from JSON appended to messages: {code}")
                    st.session_state.ace_code = code
                    debug_log("ace_code updated with new code.")

                # --- è‹¥å‹¾é¸æ·±åº¦åˆ†ææ¨¡å¼ & æœ‰ç¨‹å¼ç¢¼ -> åŸ·è¡Œç¨‹å¼ã€äºŒæ¬¡è§£æåœ–è¡¨ ---
                if st.session_state.deep_analysis_mode and code:
                    st.write("### [æ·±åº¦åˆ†æ] è‡ªå‹•åŸ·è¡Œç”¢ç”Ÿçš„ç¨‹å¼ç¢¼ä¸¦å°‡åœ–è¡¨é€è‡³ GPT-4o è§£æ...")
                    debug_log("Deep analysis mode activated.")

                    global_vars = {
                        "uploaded_file_path": st.session_state.uploaded_file_path,
                        "uploaded_image_path": st.session_state.uploaded_image_path,
                    }
                    exec_result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                    st.write("#### Execution Result")
                    st.text(exec_result)
                    debug_log(f"Execution result: {exec_result}")

                    fig = plt.gcf()
                    buf = io.BytesIO()
                    fig.savefig(buf, format="png")
                    buf.seek(0)
                    chart_base64 = base64.b64encode(buf.read()).decode("utf-8")
                    st.session_state.deep_analysis_image = chart_base64
                    debug_log("Chart has been converted to base64.")

                    # Prepare deep analysis prompt
                    prompt_2 = f"""
é€™æ˜¯ä¸€å¼µæˆ‘å¾å‰›æ‰çš„ç¨‹å¼ç¢¼ä¸­ç”¢ç”Ÿçš„åœ–è¡¨ï¼Œä»¥ä¸‹æ˜¯åœ–è¡¨çš„base64ç·¨ç¢¼ï¼š
![image](data:image/png;base64,{chart_base64})

è«‹ä½ ç‚ºæˆ‘é€²è¡Œé€²ä¸€æ­¥çš„åˆ†æï¼Œè§£é‡‹é€™å¼µåœ–è¡¨å¯èƒ½ä»£è¡¨ä»€éº¼æ¨£çš„æ•¸æ“šè¶¨å‹¢æˆ–è§€å¯Ÿã€‚
"""
                    debug_log(f"Deep Analysis Prompt: {prompt_2}")

                    # Append prompt_2 to messages
                    st.session_state.messages.append({"role": "user", "content": prompt_2})
                    debug_log("Deep analysis prompt appended to messages.")

                    # Make the API request for deep analysis
                    second_raw_response = stream_llm_response(api_key, selected_model, st.session_state.messages, temperature=0.5)
                    debug_log(f"Deep analysis response: {second_raw_response}")

                    # Append assistant response
                    st.session_state.messages.append({"role": "assistant", "content": second_raw_response})
                    st.session_state.second_response = second_raw_response
                    with st.chat_message("assistant"):
                        st.write(second_raw_response)
                        debug_log(f"Deep analysis response added to messages: {second_raw_response}")

                    # Prepare final summary prompt
                    prompt_3 = f"""
ç¬¬ä¸€éšæ®µå›è¦†å…§å®¹ï¼š{content}
ç¬¬äºŒéšæ®µåœ–è¡¨è§£æå…§å®¹ï¼š{second_raw_response}

è«‹ä½ å¹«æˆ‘æŠŠä»¥ä¸Šå…©éšæ®µçš„å…§å®¹å¥½å¥½åšä¸€å€‹æ–‡å­—ç¸½çµï¼Œä¸¦æä¾›é¡å¤–çš„å»ºè­°æˆ–è¦‹è§£ã€‚
"""
                    debug_log(f"Final Summary Prompt: {prompt_3}")

                    # Append prompt_3 to messages
                    st.session_state.messages.append({"role": "user", "content": prompt_3})
                    debug_log("Final summary prompt appended to messages.")

                    # Make the API request for final summary
                    third_raw_response = stream_llm_response(api_key, selected_model, st.session_state.messages, temperature=0.5)
                    debug_log(f"Final summary response: {third_raw_response}")

                    # Append assistant response
                    st.session_state.messages.append({"role": "assistant", "content": third_raw_response})
                    st.session_state.third_response = third_raw_response
                    with st.chat_message("assistant"):
                        st.write(third_raw_response)
                        debug_log(f"Final summary response added to messages: {third_raw_response}")

                    # Display the chart
                    st.write("#### [æ·±åº¦åˆ†æ] åœ–è¡¨ï¼š")
                    try:
                        img_data = base64.b64decode(st.session_state.deep_analysis_image)
                        st.image(img_data, caption="æ·±åº¦åˆ†æç”¢ç”Ÿçš„åœ–è¡¨", use_column_width=True)
                        debug_log("Deep analysis chart displayed.")
                    except Exception as e:
                        if st.session_state.debug_mode:
                            st.error(f"Error displaying chart: {e}")
                        debug_log(f"Error displaying chart: {e}")

            except Exception as e:
                if st.session_state.debug_mode:
                    st.error(f"An error occurred: {e}")
                debug_log(f"An error occurred: {e}")

    debug_log(f"Editor location: {st.session_state.editor_location}")
    debug_log(f"Final uploaded file path: {st.session_state.uploaded_file_path}")
    debug_log(f"Final uploaded image path: {st.session_state.uploaded_image_path}")

    # --- Persistent Code Editor ---
    if st.session_state.editor_location == "Main":
        with st.expander("ğŸ–‹ï¸ Persistent Code Editor (Main)", expanded=False):
            edited_code = st_ace(
                value=st.session_state.ace_code,
                language="python",
                theme="monokai",
                height=300,
                key="persistent_editor_main"
            )
            if edited_code != st.session_state.ace_code:
                st.session_state.ace_code = edited_code
                debug_log("ace_code updated from main editor.")

            if st.button("â–¶ï¸ Execute Code", key="execute_code_main"):
                global_vars = {
                    "uploaded_file_path": st.session_state.uploaded_file_path,
                    "uploaded_image_path": st.session_state.uploaded_image_path,
                }
                debug_log(f"Executing code with uploaded_file_path = {st.session_state.uploaded_file_path}")
                debug_log(f"Executing code with uploaded_image_path = {st.session_state.uploaded_image_path}")

                result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                st.write("### Execution Result")
                st.text(result)
                debug_log(f"Code execution result: {result}")

    else:
        with st.sidebar.expander("ğŸ–‹ï¸ Persistent Code Editor (Sidebar)", expanded=False):
            edited_code = st_ace(
                value=st.session_state.ace_code,
                language="python",
                theme="monokai",
                height=300,
                key="persistent_editor_sidebar"
            )
            if edited_code != st.session_state.ace_code:
                st.session_state.ace_code = edited_code
                debug_log("ace_code updated from sidebar editor.")

            if st.button("â–¶ï¸ Execute Code", key="execute_code_sidebar"):
                global_vars = {
                    "uploaded_file_path": st.session_state.uploaded_file_path,
                    "uploaded_image_path": st.session_state.uploaded_image_path,
                }
                debug_log(f"Executing code with uploaded_file_path = {st.session_state.uploaded_file_path}")
                debug_log(f"Executing code with uploaded_image_path = {st.session_state.uploaded_image_path}")

                result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                st.write("### Execution Result")
                st.text(result)
                debug_log(f"Code execution result: {result}")

if __name__ == "__main__":
    main()
