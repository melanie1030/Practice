import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import json
import traceback
import re
import os
import dotenv
import base64
import io
from openai import OpenAI  # ä½¿ç”¨è‡ªå®šç¾©çš„ OpenAI å®¢æˆ¶ç«¯
from streamlit_ace import st_ace

# --- Initialize and Settings ---
dotenv.load_dotenv()

UPLOAD_DIR = "uploaded_files"

OPENAI_MODELS = [
    "gpt-4o",  # å‡è¨­å¯è§£æåœ–ç‰‡çš„å¯¦é©—æ¨¡å‹
    "gpt-4-turbo",
    "gpt-3.5-turbo-16k",
    "gpt-4",
    "gpt-4-32k"
]

def debug_log(msg):
    if st.session_state.get("debug_mode", False):
        st.write(msg)
        print(msg)

def debug_error(msg):
    if st.session_state.get("debug_mode", False):
        st.error(msg)
        print(msg)

def initialize_client(api_key, model_name):
    if not api_key:
        return None
    return OpenAI(
        api_key=api_key,
        model=model_name,
        temperature=0.5
    )

def stream_llm_response(client, model_params): 
    """Stream responses from the LLM model."""
    try:
        for chunk in client.chat.completions.create(
                model=model_params.get("model", "gpt-4o"),
                messages=st.session_state.messages,
                temperature=model_params.get("temperature", 0.3),
                max_tokens=4096,
                stream=True):
            chunk_text = chunk.choices[0].delta.content or ""
            yield chunk_text
    except Exception as e:
        debug_error(f"API request failed: {e}")
        yield ""

def save_uploaded_file(uploaded_file):
    if not os.path.exists(UPLOAD_DIR):
        os.makedirs(UPLOAD_DIR)
    file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)

    debug_log(f"DEBUG: saving file to {file_path}")
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    debug_log(f"DEBUG: files in {UPLOAD_DIR}: {os.listdir(UPLOAD_DIR)}")
    return file_path

def execute_code(code, global_vars=None):
    try:
        exec_globals = global_vars if global_vars else {}
        debug_log("DEBUG: Ready to exec the following code:")
        if st.session_state.get("debug_mode", False):
            st.code(code, language="python")

        debug_log("[DEBUG] Exec code with global_vars: " + str(list(exec_globals.keys())))
        exec(code, exec_globals)
        return "Code executed successfully. Output: " + str(exec_globals.get("output", "(No output returned)"))
    except Exception as e:
        error_msg = f"Error executing code:\n{traceback.format_exc()}"
        debug_log("[DEBUG] Execution error: " + error_msg)
        if st.session_state.get("debug_mode", False):
            return error_msg
        else:
            return "Error executing code (hidden in non-debug mode)."

def extract_json_block(response: str) -> str:
    pattern = r'```(?:json)?(.*)```'
    match = re.search(pattern, response, re.DOTALL)
    if match:
        json_str = match.group(1).strip()
        return json_str
    else:
        return response.strip()

def main():
    st.set_page_config(page_title="Chatbot + Data Analysis", page_icon="ğŸ¤–", layout="wide")
    st.title("ğŸ¤– Chatbot + ğŸ“Š Data Analysis + ğŸ§  Memory + ğŸ–‹ï¸ Canvas (With Debug & Deep Analysis)")

    # Initialize session state variables
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "ace_code" not in st.session_state:
        st.session_state.ace_code = ""
    if "editor_location" not in st.session_state:
        st.session_state.editor_location = "Main"
    if "uploaded_file_path" not in st.session_state:
        st.session_state.uploaded_file_path = None
    if "uploaded_image_path" not in st.session_state:
        st.session_state.uploaded_image_path = None
    if "image_base64" not in st.session_state:
        st.session_state.image_base64 = None
    if "debug_mode" not in st.session_state:
        st.session_state.debug_mode = False
    if "deep_analysis_mode" not in st.session_state:
        st.session_state.deep_analysis_mode = False
    if "second_response" not in st.session_state:
        st.session_state.second_response = ""
    if "third_response" not in st.session_state:
        st.session_state.third_response = ""
    if "deep_analysis_image" not in st.session_state:
        st.session_state.deep_analysis_image = None

    with st.sidebar:
        st.subheader("ğŸ”’ Enter Your API Key")
        api_key = st.text_input("OpenAI API Key", type="password")

        selected_model = st.selectbox("é¸æ“‡æ¨¡å‹:", OPENAI_MODELS, index=0)

        st.session_state.debug_mode = st.checkbox("Debug Mode", value=False)
        st.session_state.deep_analysis_mode = st.checkbox("æ·±åº¦åˆ†ææ¨¡å¼", value=False)

        if "client" not in st.session_state:
            if api_key:
                st.session_state.client = initialize_client(api_key, selected_model)
                debug_log(f"DEBUG: Initialized OpenAI client with model {selected_model}")
            else:
                st.warning("â¬…ï¸ è«‹è¼¸å…¥ API Key ä»¥åˆå§‹åŒ–èŠå¤©æ©Ÿå™¨äººã€‚")

        if st.session_state.debug_mode and "client" in st.session_state:
            debug_log(f"DEBUG: Currently using model => {selected_model}")

        if st.button("ğŸ—‘ï¸ Clear Memory"):
            st.session_state.messages = []
            st.session_state.ace_code = ""
            st.session_state.uploaded_file_path = None
            st.session_state.uploaded_image_path = None
            st.session_state.image_base64 = None
            st.session_state.deep_analysis_mode = False
            st.session_state.second_response = ""
            st.session_state.third_response = ""
            st.session_state.deep_analysis_image = None
            st.success("Memory cleared!")

        st.subheader("ğŸ§  Memory State")
        if "messages" in st.session_state:
            memory_content = "\n".join([f"{msg['role']}: {msg['content']}" for msg in st.session_state.messages])
            st.text_area("Current Memory", value=memory_content, height=200)

        # --- CSV ä¸Šå‚³ ---
        st.subheader("ğŸ“‚ Upload a CSV File")
        uploaded_file = st.file_uploader("Choose a CSV file:", type=["csv"])
        csv_data = None
        if uploaded_file:
            st.session_state.uploaded_file_path = save_uploaded_file(uploaded_file)
            debug_log(f"DEBUG: st.session_state.uploaded_file_path = {st.session_state.uploaded_file_path}")
            try:
                csv_data = pd.read_csv(st.session_state.uploaded_file_path)
                st.write("### Data Preview")
                st.dataframe(csv_data)
            except Exception as e:
                if st.session_state.debug_mode:
                    st.error(f"Error reading CSV: {e}")
                debug_log(f"[DEBUG] Error reading CSV: {e}")

        # --- åœ–ç‰‡ä¸Šå‚³ ---
        st.subheader("ğŸ–¼ï¸ Upload an Image")
        uploaded_image = st.file_uploader("Choose an image:", type=["png", "jpg", "jpeg"])
        if uploaded_image:
            st.session_state.uploaded_image_path = save_uploaded_file(uploaded_image)
            debug_log(f"DEBUG: st.session_state.uploaded_image_path = {st.session_state.uploaded_image_path}")

            st.image(st.session_state.uploaded_image_path, caption="Uploaded Image Preview", use_column_width=True)
            try:
                with open(st.session_state.uploaded_image_path, "rb") as f:
                    img_bytes = f.read()
                st.session_state.image_base64 = base64.b64encode(img_bytes).decode("utf-8")
                debug_log("DEBUG: Image has been converted to base64.")
            except Exception as e:
                if st.session_state.debug_mode:
                    st.error(f"Error converting image to base64: {e}")
                debug_log(f"[DEBUG] Error converting image to base64: {e}")

        st.subheader("Editor Location")
        location = st.radio(
            "Choose where to display the editor:",
            ["Main", "Sidebar"],
            index=0 if st.session_state.editor_location == "Main" else 1
        )
        st.session_state.editor_location = location

    # --- é¡¯ç¤ºæ­·å²è¨Šæ¯ ---
    for message in st.session_state.messages:
        if message["role"] == "user":
            with st.chat_message("user"):
                st.write(message["content"])
        elif message["role"] == "assistant":
            with st.chat_message("assistant"):
                if "content" in message:
                    st.write(message["content"])
                if "code" in message:
                    st.code(message["code"], language="python")

    user_input = st.chat_input("Hi! Ask me anything...")
    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.write(user_input)

        if "client" not in st.session_state or st.session_state.client is None:
            st.error("OpenAI client is not initialized. Please enter a valid API Key.")
        else:
            with st.spinner("Thinking..."):
                try:
                    debug_log(f"DEBUG: Currently st.session_state.uploaded_file_path = {st.session_state.uploaded_file_path}")
                    debug_log(f"DEBUG: Currently st.session_state.uploaded_image_path = {st.session_state.uploaded_image_path}")

                    # --- æ±ºå®šä½¿ç”¨å“ªç¨® prompt ---
                    if st.session_state.uploaded_image_path is not None and st.session_state.image_base64:
                        # [æƒ…å¢ƒ] æœ‰ä¸Šå‚³åœ–ç‰‡ -> åªçµ¦ user_input èˆ‡ åœ–ç‰‡ Base64
                        # é¿å…å°‡ CSV & JSON æ ¼å¼ä¹Ÿæ··é€²å»
                        prompt = f"User input: {user_input}\nHere is the image data in base64:\n{st.session_state.image_base64[:300]}..."
                    else:
                        # [æƒ…å¢ƒ] æ²’æœ‰ä¸Šå‚³åœ–ç‰‡ -> ç¶­æŒèˆŠæœ‰è¤‡é›œ JSON é‚è¼¯
                        if st.session_state.uploaded_file_path is not None:
                            try:
                                df_temp = pd.read_csv(st.session_state.uploaded_file_path)
                                csv_columns = ", ".join(df_temp.columns)
                            except Exception as e:
                                csv_columns = "ç„¡æ³•è®€å–æ¬„ä½"
                                if st.session_state.debug_mode:
                                    st.error(f"Error reading columns: {e}")
                                debug_log(f"[DEBUG] Error reading columns: {e}")
                        else:
                            csv_columns = "ç„¡ä¸Šå‚³æª”æ¡ˆ"

                        if st.session_state.uploaded_file_path is not None and csv_columns != "ç„¡ä¸Šå‚³æª”æ¡ˆ":
                            prompt = f"""Please respond with a JSON object in the format:
{{
    "content": "é€™æ˜¯æˆ‘çš„è§€å¯Ÿï¼š{{{{åˆ†æå…§å®¹}}}}",
    "code": "import pandas as pd\\nimport streamlit as st\\nimport matplotlib.pyplot as plt\\n# è®€å– CSV æª”æ¡ˆ (è«‹ç›´æ¥ä½¿ç”¨ st.session_state.uploaded_file_path è®Šæ•¸)\\ndata = pd.read_csv(st.session_state.uploaded_file_path)\\n\\n# åœ¨é€™è£¡åŠ å…¥ä½ è¦çš„ç¹ªåœ–æˆ–åˆ†æé‚è¼¯\\n\\n# ä¾‹å¦‚ä½¿ç”¨ st.pyplot() ä¾†é¡¯ç¤ºåœ–è¡¨:\\n# fig, ax = plt.subplots()\\n# ax.scatter(data['colA'], data['colB'])\\n# st.pyplot(fig)\\n"
}}
Important:
1) Must use st.session_state.uploaded_file_path as the CSV path (instead of a hardcoded path)
2) Must use st.pyplot() to display any matplotlib figure
3) Return only valid JSON (escape any special characters if needed)

Based on the request: {user_input}.
Available columns: {csv_columns}.
"""
                        else:
                            prompt = f"è«‹å…¨éƒ¨ä»¥ç¹é«”ä¸­æ–‡å›ç­”æ­¤å•é¡Œï¼š{user_input}"

                    debug_log(f"DEBUG: Prompt used => {prompt}")

                    # Append the prompt to messages
                    st.session_state.messages.append({"role": "system", "content": prompt})

                    # Get the model parameters
                    model_params = {
                        "model": st.session_state.client.model,
                        "temperature": st.session_state.client.temperature
                    }

                    # Stream the response
                    response_content = ""
                    response_code = ""
                    for chunk in stream_llm_response(st.session_state.client, model_params):
                        response_content += chunk
                        st.chat_message("assistant").write(chunk)
                        st.experimental_rerun()  # To display the streaming content

                    # After streaming is complete, process the full response
                    json_str = extract_json_block(response_content)
                    try:
                        response_json = json.loads(json_str)
                    except Exception as e:
                        debug_log(f"json.loads parsing error: {e}")
                        debug_error(f"json.loads parsing error: {e}")
                        response_json = {"content": response_content, "code": ""}

                    content = response_json.get("content", "é€™æ˜¯æˆ‘çš„åˆ†æï¼š")
                    st.session_state.messages.append({"role": "assistant", "content": content})
                    with st.chat_message("assistant"):
                        st.write(content)

                    code = response_json.get("code", "")
                    if code:
                        st.session_state.messages.append({"role": "assistant", "code": code})
                        with st.chat_message("assistant"):
                            st.code(code, language="python")
                        st.session_state.ace_code = code

                    # --- è‹¥å‹¾é¸æ·±åº¦åˆ†ææ¨¡å¼ & æœ‰ç¨‹å¼ç¢¼ -> åŸ·è¡Œç¨‹å¼ã€äºŒæ¬¡è§£æåœ–è¡¨ ---
                    if st.session_state.deep_analysis_mode and code:
                        st.write("### [æ·±åº¦åˆ†æ] è‡ªå‹•åŸ·è¡Œç”¢ç”Ÿçš„ç¨‹å¼ç¢¼ä¸¦å°‡åœ–è¡¨é€è‡³ GPT-4o è§£æ...")

                        global_vars = {
                            "uploaded_file_path": st.session_state.uploaded_file_path,
                            "uploaded_image_path": st.session_state.uploaded_image_path,
                        }
                        exec_result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                        st.write("#### Execution Result")
                        st.text(exec_result)

                        fig = plt.gcf()
                        buf = io.BytesIO()
                        fig.savefig(buf, format="png")
                        buf.seek(0)
                        chart_base64 = base64.b64encode(buf.read()).decode("utf-8")
                        st.session_state.deep_analysis_image = chart_base64

                        deep_model = initialize_client(st.session_state.client.api_key, "gpt-4o")
                        if deep_model:
                            prompt_2 = f"""
é€™æ˜¯ä¸€å¼µæˆ‘å¾å‰›æ‰çš„ç¨‹å¼ç¢¼ä¸­ç”¢ç”Ÿçš„åœ–è¡¨ï¼Œä»¥ä¸‹æ˜¯åœ–è¡¨çš„base64ç·¨ç¢¼ï¼š
{chart_base64[:300]}...

è«‹ä½ ç‚ºæˆ‘é€²è¡Œé€²ä¸€æ­¥çš„åˆ†æï¼Œè§£é‡‹é€™å¼µåœ–è¡¨å¯èƒ½ä»£è¡¨ä»€éº¼æ¨£çš„æ•¸æ“šè¶¨å‹¢æˆ–è§€å¯Ÿã€‚
"""
                            debug_log(f"DEBUG: Deep Analysis Prompt => {prompt_2}")
                            st.session_state.messages.append({"role": "system", "content": prompt_2})

                            # Stream the second response
                            second_raw_response = ""
                            for chunk in stream_llm_response(deep_model, {"model": "gpt-4o", "temperature": 0.5}):
                                second_raw_response += chunk
                                st.chat_message("assistant").write(chunk)
                                st.experimental_rerun()

                            st.session_state.second_response = second_raw_response

                            st.write("#### [æ·±åº¦åˆ†æ] åœ–è¡¨è§£æçµæœ (ç¬¬äºŒæ¬¡å›è¦†) :")
                            st.write(second_raw_response)

                            final_model = initialize_client(st.session_state.client.api_key, "gpt-4o")
                            if final_model:
                                prompt_3 = f"""
ç¬¬ä¸€éšæ®µå›è¦†å…§å®¹ï¼š{content}
ç¬¬äºŒéšæ®µåœ–è¡¨è§£æå…§å®¹ï¼š{second_raw_response}

è«‹ä½ å¹«æˆ‘æŠŠä»¥ä¸Šå…©éšæ®µçš„å…§å®¹å¥½å¥½åšä¸€å€‹æ–‡å­—ç¸½çµï¼Œä¸¦æä¾›é¡å¤–çš„å»ºè­°æˆ–è¦‹è§£ã€‚
"""
                                debug_log(f"DEBUG: Final Summary Prompt => {prompt_3}")
                                st.session_state.messages.append({"role": "system", "content": prompt_3})

                                # Stream the third response
                                third_raw_response = ""
                                for chunk in stream_llm_response(final_model, {"model": "gpt-4o", "temperature": 0.5}):
                                    third_raw_response += chunk
                                    st.chat_message("assistant").write(chunk)
                                    st.experimental_rerun()

                                st.session_state.third_response = third_raw_response

                                st.write("#### [æ·±åº¦åˆ†æ] çµè«– (ç¬¬ä¸‰æ¬¡å›è¦†) :")
                                st.write(third_raw_response)

                                st.write("#### [æ·±åº¦åˆ†æ] åœ–è¡¨ï¼š")
                                img_data = base64.b64decode(st.session_state.deep_analysis_image)
                                st.image(img_data, caption="æ·±åº¦åˆ†æç”¢ç”Ÿçš„åœ–è¡¨", use_column_width=True)

                except Exception as e:
                    if st.session_state.debug_mode:
                        st.error(f"An error occurred: {e}")
                    debug_log(f"[DEBUG] An error occurred: {e}")

    debug_log(f"DEBUG: editor_location = {st.session_state.editor_location}")
    debug_log(f"DEBUG: final st.session_state.uploaded_file_path = {st.session_state.uploaded_file_path}")
    debug_log(f"DEBUG: final st.session_state.uploaded_image_path = {st.session_state.uploaded_image_path}")

    if st.session_state.editor_location == "Main":
        with st.expander("ğŸ–‹ï¸ Persistent Code Editor (Main)", expanded=False):
            edited_code = st_ace(
                value=st.session_state.ace_code,
                language="python",
                theme="monokai",
                height=300,
                key="persistent_editor_main"
            )
            if edited_code != st.session_state.ace_code:
                st.session_state.ace_code = edited_code

            if st.button("â–¶ï¸ Execute Code", key="execute_code_main"):
                global_vars = {
                    "uploaded_file_path": st.session_state.uploaded_file_path,
                    "uploaded_image_path": st.session_state.uploaded_image_path,
                }
                debug_log(f"DEBUG: executing code with uploaded_file_path = {st.session_state.uploaded_file_path}")
                debug_log(f"DEBUG: executing code with uploaded_image_path = {st.session_state.uploaded_image_path}")

                result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                st.write("### Execution Result")
                st.text(result)

    else:
        with st.sidebar.expander("ğŸ–‹ï¸ Persistent Code Editor (Sidebar)", expanded=False):
            edited_code = st_ace(
                value=st.session_state.ace_code,
                language="python",
                theme="monokai",
                height=300,
                key="persistent_editor_sidebar"
            )
            if edited_code != st.session_state.ace_code:
                st.session_state.ace_code = edited_code

            if st.button("â–¶ï¸ Execute Code", key="execute_code_sidebar"):
                global_vars = {
                    "uploaded_file_path": st.session_state.uploaded_file_path,
                    "uploaded_image_path": st.session_state.uploaded_image_path,
                }
                debug_log(f"DEBUG: executing code with uploaded_file_path = {st.session_state.uploaded_file_path}")
                debug_log(f"DEBUG: executing code with uploaded_image_path = {st.session_state.uploaded_image_path}")

                result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                st.write("### Execution Result")
                st.text(result)

if __name__ == "__main__":
    main()
