import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import json
import traceback
import re
import os
import dotenv
import base64
import io
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain.chat_models import ChatOpenAI
from streamlit_ace import st_ace

# --- é€™è£¡åŒ¯å…¥ openai ä»¥ä¾¿ç”¨ client.chat.completions.create ---
import openai

# --- Initialize and Settings ---
dotenv.load_dotenv()

UPLOAD_DIR = "uploaded_files"

OPENAI_MODELS = [
    "gpt-4o",  # å‡è¨­å¯è§£æåœ–ç‰‡çš„å¯¦é©—æ¨¡å‹
    "gpt-4-turbo",
    "gpt-3.5-turbo-16k",
    "gpt-4",
    "gpt-4-32k"
]

def debug_log(msg):
    if st.session_state.get("debug_mode", False):
        st.write(msg)
        print(msg)

def debug_error(msg):
    if st.session_state.get("debug_mode", False):
        st.error(msg)
        print(msg)

def initialize_client(api_key, model_name):
    return ChatOpenAI(
        model=model_name,
        temperature=0.5,
        openai_api_key=api_key
    ) if api_key else None

def save_uploaded_file(uploaded_file):
    if not os.path.exists(UPLOAD_DIR):
        os.makedirs(UPLOAD_DIR)
    file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)

    debug_log(f"DEBUG: saving file to {file_path}")
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    debug_log(f"DEBUG: files in {UPLOAD_DIR}: {os.listdir(UPLOAD_DIR)}")
    return file_path

def execute_code(code, global_vars=None):
    try:
        exec_globals = global_vars if global_vars else {}
        debug_log("DEBUG: Ready to exec the following code:")
        if st.session_state.get("debug_mode", False):
            st.code(code, language="python")

        debug_log("[DEBUG] Exec code with global_vars: " + str(list(exec_globals.keys())))
        exec(code, exec_globals)
        return "Code executed successfully. Output: " + str(exec_globals.get("output", "(No output returned)"))
    except Exception as e:
        error_msg = f"Error executing code:\n{traceback.format_exc()}"
        debug_log("[DEBUG] Execution error: " + error_msg)
        if st.session_state.get("debug_mode", False):
            return error_msg
        else:
            return "Error executing code (hidden in non-debug mode)."

def extract_json_block(response: str) -> str:
    pattern = r'```(?:json)?(.*)```'
    match = re.search(pattern, response, re.DOTALL)
    if match:
        json_str = match.group(1).strip()
        return json_str
    else:
        return response.strip()

def main():
    st.set_page_config(page_title="Chatbot + Data Analysis", page_icon="ğŸ¤–", layout="wide")
    st.title("ğŸ¤– Chatbot + ğŸ“Š Data Analysis + ğŸ§  Memory + ğŸ–‹ï¸ Canvas (With Debug & Deep Analysis)")

    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "ace_code" not in st.session_state:
        st.session_state.ace_code = ""
    if "editor_location" not in st.session_state:
        st.session_state.editor_location = "Main"
    if "uploaded_file_path" not in st.session_state:
        st.session_state.uploaded_file_path = None
    if "uploaded_image_path" not in st.session_state:
        st.session_state.uploaded_image_path = None
    if "image_base64" not in st.session_state:
        st.session_state.image_base64 = None
    if "debug_mode" not in st.session_state:
        st.session_state.debug_mode = False
    if "deep_analysis_mode" not in st.session_state:
        st.session_state.deep_analysis_mode = False
    if "second_response" not in st.session_state:
        st.session_state.second_response = ""
    if "third_response" not in st.session_state:
        st.session_state.third_response = ""
    if "deep_analysis_image" not in st.session_state:
        st.session_state.deep_analysis_image = None

    with st.sidebar:
        st.subheader("ğŸ”’ Enter Your API Key")
        api_key = st.text_input("OpenAI API Key", type="password")

        selected_model = st.selectbox("é¸æ“‡æ¨¡å‹:", OPENAI_MODELS, index=0)

        st.session_state.debug_mode = st.checkbox("Debug Mode", value=False)
        st.session_state.deep_analysis_mode = st.checkbox("æ·±åº¦åˆ†ææ¨¡å¼", value=False)

        # åˆå§‹åŒ– langchain å°è©±
        if "conversation" not in st.session_state:
            if api_key:
                st.session_state.chat_model = initialize_client(api_key, selected_model)
                st.session_state.memory = ConversationBufferMemory()
                st.session_state.conversation = ConversationChain(
                    llm=st.session_state.chat_model,
                    memory=st.session_state.memory
                )
            else:
                st.warning("â¬…ï¸ è«‹è¼¸å…¥ API Key ä»¥åˆå§‹åŒ–èŠå¤©æ©Ÿå™¨äººã€‚")
                return

        if st.session_state.debug_mode:
            debug_log(f"DEBUG: Currently using model => {selected_model}")

        # è¨­å®š openai.api_key (ç”¨æ–¼ã€Œåªæœ‰åœ–ç‰‡æ™‚ã€çš„ streaming API)
        openai.api_key = api_key

        if st.button("ğŸ—‘ï¸ Clear Memory"):
            st.session_state.memory.clear()
            st.session_state.messages = []
            st.session_state.ace_code = ""
            st.session_state.uploaded_file_path = None
            st.session_state.uploaded_image_path = None
            st.session_state.image_base64 = None
            st.session_state.deep_analysis_mode = False
            st.session_state.second_response = ""
            st.session_state.third_response = ""
            st.session_state.deep_analysis_image = None
            st.success("Memory cleared!")

        st.subheader("ğŸ§  Memory State")
        if "memory" in st.session_state:
            memory_content = st.session_state.memory.load_memory_variables({})
            st.text_area("Current Memory", value=str(memory_content), height=200)

        # --- CSV ä¸Šå‚³ ---
        st.subheader("ğŸ“‚ Upload a CSV File")
        uploaded_file = st.file_uploader("Choose a CSV file:", type=["csv"])
        csv_data = None
        if uploaded_file:
            st.session_state.uploaded_file_path = save_uploaded_file(uploaded_file)
            debug_log(f"DEBUG: st.session_state.uploaded_file_path = {st.session_state.uploaded_file_path}")
            try:
                csv_data = pd.read_csv(st.session_state.uploaded_file_path)
                st.write("### Data Preview")
                st.dataframe(csv_data)
            except Exception as e:
                if st.session_state.debug_mode:
                    st.error(f"Error reading CSV: {e}")
                debug_log(f"[DEBUG] Error reading CSV: {e}")

        # --- åœ–ç‰‡ä¸Šå‚³ ---
        st.subheader("ğŸ–¼ï¸ Upload an Image")
        uploaded_image = st.file_uploader("Choose an image:", type=["png", "jpg", "jpeg"])
        if uploaded_image:
            st.session_state.uploaded_image_path = save_uploaded_file(uploaded_image)
            debug_log(f"DEBUG: st.session_state.uploaded_image_path = {st.session_state.uploaded_image_path}")

            st.image(st.session_state.uploaded_image_path, caption="Uploaded Image Preview", use_column_width=True)
            try:
                with open(st.session_state.uploaded_image_path, "rb") as f:
                    img_bytes = f.read()
                st.session_state.image_base64 = base64.b64encode(img_bytes).decode("utf-8")
                debug_log("DEBUG: Image has been converted to base64.")
            except Exception as e:
                if st.session_state.debug_mode:
                    st.error(f"Error converting image to base64: {e}")
                debug_log(f"[DEBUG] Error converting image to base64: {e}")

        st.subheader("Editor Location")
        location = st.radio(
            "Choose where to display the editor:",
            ["Main", "Sidebar"],
            index=0 if st.session_state.editor_location == "Main" else 1
        )
        st.session_state.editor_location = location

    # --- é¡¯ç¤ºæ­·å²è¨Šæ¯ ---
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if "content" in message:
                st.write(message["content"])
            if "code" in message:
                st.code(message["code"], language="python")

    # --- ä½¿ç”¨è€…è¼¸å…¥ ---
    user_input = st.chat_input("Hi! Ask me anything...")
    if user_input:
        # å…ˆåœ¨å°è©±è¨˜æ†¶ä¸­åŠ ä¸Šä½¿ç”¨è€…è¨Šæ¯
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.write(user_input)

        with st.spinner("Thinking..."):
            try:
                debug_log(f"DEBUG: Currently st.session_state.uploaded_file_path = {st.session_state.uploaded_file_path}")
                debug_log(f"DEBUG: Currently st.session_state.uploaded_image_path = {st.session_state.uploaded_image_path}")

                # ================
                # 1) å¦‚æœåªæœ‰ã€Œåœ–ç‰‡ã€æ²’æœ‰ã€ŒCSVã€ï¼Œå‰‡æ”¹ç”¨ openai çš„ stream API ä¾†å›æ‡‰
                # ================
                if (st.session_state.uploaded_image_path is not None) and (st.session_state.uploaded_file_path is None):
                    # ç‚ºäº†è®“æ¨¡å‹çŸ¥é“ä½¿ç”¨è€…çš„åœ–ç‰‡å…§å®¹ï¼Œæˆ‘å€‘æŠŠ base64 (æˆ–æ–‡å­—æè¿°) ä¹Ÿä¸€ä½µé™„åŠ åˆ°æœ€å¾Œä¸€ç­† user message
                    # ï¼ˆæ­¤è™•ç‚ºäº†ä¿è­‰å°è©±ä¸Šä¸‹æ–‡ï¼Œæˆ‘å€‘å°±æŠŠ base64 ç›´æ¥æ¥åˆ° user_input å¾Œï¼‰
                    last_msg_index = len(st.session_state.messages) - 1
                    if last_msg_index >= 0:
                        new_content = (
                            f"{st.session_state.messages[last_msg_index]['content']}\n"
                            f"Here is the image data in base64:\n{st.session_state.image_base64}"
                        )
                        st.session_state.messages[last_msg_index]["content"] = new_content

                    # æ¥è‘—ç”¨ openai åŸç”Ÿ API åš streaming
                    # å…ˆæº–å‚™ openai éœ€è¦çš„ messages çµæ§‹
                    # LangChain çš„å°è©±è¨˜æ†¶ messages å…¶å¯¦å·²ç¶“æ˜¯ [{"role": "...", "content": "..."}] ç›¸å®¹çµæ§‹ï¼Œå¯ç›´æ¥ç”¨
                    openai_messages = st.session_state.messages

                    # æº–å‚™å‘¼å«åƒæ•¸
                    model_params = {
                        "model": selected_model if selected_model else "gpt-4o",
                        "temperature": 0.3
                    }

                    # å‘¼å« streaming
                    response_text = ""
                    with st.chat_message("assistant"):
                        stream_placeholder = st.empty()
                        for chunk in openai.ChatCompletion.create(
                            model=model_params.get("model", "gpt-4o"),
                            messages=openai_messages,
                            temperature=model_params.get("temperature", 0.3),
                            max_tokens=4096
                        ):
                            chunk_delta = chunk["choices"][0].get("delta", {})
                            chunk_text = chunk_delta.get("content", "")
                            if chunk_text:
                                response_text += chunk_text
                                # å³æ™‚æ›´æ–°ç•«é¢
                                stream_placeholder.markdown(response_text)

                    # å°‡æ¨¡å‹æœ€çµ‚å›æ‡‰å¯«å…¥å°è©±è¨˜æ†¶
                    st.session_state.messages.append({"role": "assistant", "content": response_text})

                else:
                    # ================
                    # 2) å¦å‰‡ï¼ˆæœ‰ CSV æˆ–è€…æ²’æœ‰ä»»ä½•æª”æ¡ˆï¼‰ï¼Œç¶­æŒèˆŠæœ‰ JSON+LangChain æ–¹å¼
                    # ================
                    if st.session_state.uploaded_image_path is not None and st.session_state.image_base64:
                        # [æƒ…å¢ƒ] æœ‰ä¸Šå‚³åœ–ç‰‡ + ä¸ç¬¦åˆã€Œåªæœ‰åœ–ç‰‡æ²’ csvã€æ¢ä»¶(ä»£è¡¨ä¹Ÿä¸Šå‚³äº†csv?)ï¼Œç¶­æŒèˆŠé‚è¼¯
                        prompt = f"User input: {user_input}\nHere is the image data in base64:\n{st.session_state.image_base64}..."
                    else:
                        # [æƒ…å¢ƒ] æ²’æœ‰åœ–ç‰‡ or æœ‰CSV
                        if st.session_state.uploaded_file_path is not None:
                            try:
                                df_temp = pd.read_csv(st.session_state.uploaded_file_path)
                                csv_columns = ", ".join(df_temp.columns)
                            except Exception as e:
                                csv_columns = "ç„¡æ³•è®€å–æ¬„ä½"
                                if st.session_state.debug_mode:
                                    st.error(f"Error reading columns: {e}")
                                debug_log(f"[DEBUG] Error reading columns: {e}")
                        else:
                            csv_columns = "ç„¡ä¸Šå‚³æª”æ¡ˆ"

                        prompt = f"""Please respond with a JSON object in the format:
{{
    "content": "é€™æ˜¯æˆ‘çš„è§€å¯Ÿï¼š{{{{åˆ†æå…§å®¹}}}}",
    "code": "import pandas as pd\\nimport streamlit as st\\nimport matplotlib.pyplot as plt\\n# è®€å– CSV æª”æ¡ˆ (è«‹ç›´æ¥ä½¿ç”¨ st.session_state.uploaded_file_path è®Šæ•¸)\\ndata = pd.read_csv(st.session_state.uploaded_file_path)\\n\\n# åœ¨é€™è£¡åŠ å…¥ä½ è¦çš„ç¹ªåœ–æˆ–åˆ†æé‚è¼¯\\n\\n# ä¾‹å¦‚ä½¿ç”¨ st.pyplot() ä¾†é¡¯ç¤ºåœ–è¡¨:\\n# fig, ax = plt.subplots()\\n# ax.scatter(data['colA'], data['colB'])\\n# st.pyplot(fig)\\n"
}}
Important:
1) Must use st.session_state.uploaded_file_path as the CSV path (instead of a hardcoded path)
2) Must use st.pyplot() to display any matplotlib figure
3) Return only valid JSON (escape any special characters if needed)

Based on the request: {user_input}.
Available columns: {csv_columns}.
"""

                        if csv_columns == "ç„¡ä¸Šå‚³æª”æ¡ˆ":
                            prompt = f"è«‹å…¨éƒ¨ä»¥ç¹é«”ä¸­æ–‡å›ç­”æ­¤å•é¡Œï¼š{user_input}"

                    debug_log(f"DEBUG: Prompt used => {prompt}")

                    raw_response = st.session_state.conversation.run(prompt)
                    if st.session_state.debug_mode:
                        st.write("Model raw response:", raw_response)
                    debug_log(f"[DEBUG] Model raw response => {raw_response}")

                    # å˜—è©¦æ“·å– JSON å€å¡Š
                    json_str = extract_json_block(raw_response)
                    try:
                        response_json = json.loads(json_str)
                    except Exception as e:
                        debug_log(f"json.loads parsing error: {e}")
                        debug_error(f"json.loads parsing error: {e}")
                        response_json = {"content": json_str, "code": ""}

                    content = response_json.get("content", "é€™æ˜¯æˆ‘çš„åˆ†æï¼š")
                    st.session_state.messages.append({"role": "assistant", "content": content})
                    with st.chat_message("assistant"):
                        st.write(content)

                    code = response_json.get("code", "")
                    if code:
                        st.session_state.messages.append({"role": "assistant", "code": code})
                        with st.chat_message("assistant"):
                            st.code(code, language="python")
                        st.session_state.ace_code = code

                    # --- è‹¥å‹¾é¸æ·±åº¦åˆ†ææ¨¡å¼ & æœ‰ç¨‹å¼ç¢¼ -> åŸ·è¡Œç¨‹å¼ã€äºŒæ¬¡è§£æåœ–è¡¨ ---
                    if st.session_state.deep_analysis_mode and code:
                        st.write("### [æ·±åº¦åˆ†æ] è‡ªå‹•åŸ·è¡Œç”¢ç”Ÿçš„ç¨‹å¼ç¢¼ä¸¦å°‡åœ–è¡¨é€è‡³ GPT-4o è§£æ...")

                        global_vars = {
                            "uploaded_file_path": st.session_state.uploaded_file_path,
                            "uploaded_image_path": st.session_state.uploaded_image_path,
                        }
                        exec_result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                        st.write("#### Execution Result")
                        st.text(exec_result)

                        fig = plt.gcf()
                        buf = io.BytesIO()
                        fig.savefig(buf, format="png")
                        buf.seek(0)
                        chart_base64 = base64.b64encode(buf.read()).decode("utf-8")
                        st.session_state.deep_analysis_image = chart_base64

                        deep_model = ChatOpenAI(
                            model="gpt-4o",
                            temperature=0.5,
                            openai_api_key=api_key
                        ) if api_key else None
                        if deep_model:
                            prompt_2 = f"""
é€™æ˜¯ä¸€å¼µæˆ‘å¾å‰›æ‰çš„ç¨‹å¼ç¢¼ä¸­ç”¢ç”Ÿçš„åœ–è¡¨ï¼Œä»¥ä¸‹æ˜¯åœ–è¡¨çš„base64ç·¨ç¢¼ï¼š
{chart_base64[:300]}...

è«‹ä½ ç‚ºæˆ‘é€²è¡Œé€²ä¸€æ­¥çš„åˆ†æï¼Œè§£é‡‹é€™å¼µåœ–è¡¨å¯èƒ½ä»£è¡¨ä»€éº¼æ¨£çš„æ•¸æ“šè¶¨å‹¢æˆ–è§€å¯Ÿã€‚
"""
                            debug_log(f"DEBUG: Deep Analysis Prompt => {prompt_2}")
                            second_raw_response = deep_model.call_as_llm(prompt_2)
                            st.session_state.second_response = second_raw_response

                            st.write("#### [æ·±åº¦åˆ†æ] åœ–è¡¨è§£æçµæœ (ç¬¬äºŒæ¬¡å›è¦†) :")
                            st.write(second_raw_response)

                            final_model = ChatOpenAI(
                                model="gpt-4o",
                                temperature=0.5,
                                openai_api_key=api_key
                            ) if api_key else None
                            if final_model:
                                prompt_3 = f"""
ç¬¬ä¸€éšæ®µå›è¦†å…§å®¹ï¼š{content}
ç¬¬äºŒéšæ®µåœ–è¡¨è§£æå…§å®¹ï¼š{second_raw_response}

è«‹ä½ å¹«æˆ‘æŠŠä»¥ä¸Šå…©éšæ®µçš„å…§å®¹å¥½å¥½åšä¸€å€‹æ–‡å­—ç¸½çµï¼Œä¸¦æä¾›é¡å¤–çš„å»ºè­°æˆ–è¦‹è§£ã€‚
"""
                                debug_log(f"DEBUG: Final Summary Prompt => {prompt_3}")
                                third_raw_response = final_model.call_as_llm(prompt_3)
                                st.session_state.third_response = third_raw_response

                                st.write("#### [æ·±åº¦åˆ†æ] çµè«– (ç¬¬ä¸‰æ¬¡å›è¦†) :")
                                st.write(third_raw_response)

                                st.write("#### [æ·±åº¦åˆ†æ] åœ–è¡¨ï¼š")
                                img_data = base64.b64decode(st.session_state.deep_analysis_image)
                                st.image(img_data, caption="æ·±åº¦åˆ†æç”¢ç”Ÿçš„åœ–è¡¨", use_column_width=True)

            except Exception as e:
                if st.session_state.debug_mode:
                    st.error(f"An error occurred: {e}")
                debug_log(f"[DEBUG] An error occurred: {e}")

    debug_log(f"DEBUG: editor_location = {st.session_state.editor_location}")
    debug_log(f"DEBUG: final st.session_state.uploaded_file_path = {st.session_state.uploaded_file_path}")
    debug_log(f"DEBUG: final st.session_state.uploaded_image_path = {st.session_state.uploaded_image_path}")

    if st.session_state.editor_location == "Main":
        with st.expander("ğŸ–‹ï¸ Persistent Code Editor (Main)", expanded=False):
            edited_code = st_ace(
                value=st.session_state.ace_code,
                language="python",
                theme="monokai",
                height=300,
                key="persistent_editor_main"
            )
            if edited_code != st.session_state.ace_code:
                st.session_state.ace_code = edited_code

            if st.button("â–¶ï¸ Execute Code", key="execute_code_main"):
                global_vars = {
                    "uploaded_file_path": st.session_state.uploaded_file_path,
                    "uploaded_image_path": st.session_state.uploaded_image_path,
                }
                debug_log(f"DEBUG: executing code with uploaded_file_path = {st.session_state.uploaded_file_path}")
                debug_log(f"DEBUG: executing code with uploaded_image_path = {st.session_state.uploaded_image_path}")

                result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                st.write("### Execution Result")
                st.text(result)

    else:
        with st.sidebar.expander("ğŸ–‹ï¸ Persistent Code Editor (Sidebar)", expanded=False):
            edited_code = st_ace(
                value=st.session_state.ace_code,
                language="python",
                theme="monokai",
                height=300,
                key="persistent_editor_sidebar"
            )
            if edited_code != st.session_state.ace_code:
                st.session_state.ace_code = edited_code

            if st.button("â–¶ï¸ Execute Code", key="execute_code_sidebar"):
                global_vars = {
                    "uploaded_file_path": st.session_state.uploaded_file_path,
                    "uploaded_image_path": st.session_state.uploaded_image_path,
                }
                debug_log(f"DEBUG: executing code with uploaded_file_path = {st.session_state.uploaded_file_path}")
                debug_log(f"DEBUG: executing code with uploaded_image_path = {st.session_state.uploaded_image_path}")

                result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                st.write("### Execution Result")
                st.text(result)

if __name__ == "__main__":
    main()
