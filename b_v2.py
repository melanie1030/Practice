import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import json
import traceback
import re
import os
import dotenv
import base64
import io

# -- LangChain ç›¸é—œ --
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain.chat_models import ChatOpenAI

# -- Editor --
from streamlit_ace import st_ace

# -- ä»¥ä¸‹ç‚ºæ‚¨æ¸¬è©¦æˆåŠŸçš„ openai<1.0.0 æ–¹å¼ --
from openai import OpenAI
from PIL import Image
from audio_recorder_streamlit import audio_recorder  # å¦‚æœæœ‰éœ€è¦ä¿ç•™éŒ„éŸ³åŠŸèƒ½ï¼Œå¯ä¿ç•™
import random

# --- dotenv åŠ è¼‰ç’°å¢ƒ ---
dotenv.load_dotenv()

# === å…¨åŸŸè¨­å®š ===
UPLOAD_DIR = "uploaded_files"

OPENAI_MODELS = [
    "gpt-4o",       # å‡è¨­å¯è§£æåœ–ç‰‡çš„å¯¦é©—æ¨¡å‹
    "gpt-4-turbo",
    "gpt-3.5-turbo-16k",
    "gpt-4",
    "gpt-4-32k"
]

# -------------------------------------------------
# ä»¥ä¸‹å€å¡Š: b_v2.py è£¡çš„è¼”åŠ©å‡½å¼
# -------------------------------------------------
def debug_log(msg):
    if st.session_state.get("debug_mode", False):
        st.write(msg)
        print(msg)

def debug_error(msg):
    if st.session_state.get("debug_mode", False):
        st.error(msg)
        print(msg)

def initialize_client(api_key, model_name):
    """
    åŸ b_v2 ç”¨ LangChain ChatOpenAI
    """
    return ChatOpenAI(
        model=model_name,
        temperature=0.5,
        openai_api_key=api_key
    ) if api_key else None

def save_uploaded_file(uploaded_file):
    """å°‡ä¸Šå‚³æª”æ¡ˆå­˜è‡³æŒ‡å®šè³‡æ–™å¤¾"""
    if not os.path.exists(UPLOAD_DIR):
        os.makedirs(UPLOAD_DIR)
    file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)
    debug_log(f"DEBUG: saving file to {file_path}")
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    debug_log(f"DEBUG: files in {UPLOAD_DIR}: " + str(os.listdir(UPLOAD_DIR)))
    return file_path

def execute_code(code, global_vars=None):
    """åŸ·è¡Œä½¿ç”¨è€…ç”¢ç”Ÿçš„Pythonç¨‹å¼ç¢¼"""
    try:
        exec_globals = global_vars if global_vars else {}
        debug_log("DEBUG: Ready to exec the following code:")
        if st.session_state.get("debug_mode", False):
            st.code(code, language="python")

        debug_log("[DEBUG] Exec code with global_vars: " + str(list(exec_globals.keys())))
        exec(code, exec_globals)
        return "Code executed successfully. Output: " + str(exec_globals.get("output", "(No output returned)"))
    except Exception as e:
        error_msg = f"Error executing code:\n{traceback.format_exc()}"
        debug_log("[DEBUG] Execution error: " + error_msg)
        if st.session_state.get("debug_mode", False):
            return error_msg
        else:
            return "Error executing code (hidden in non-debug mode)."

def extract_json_block(response: str) -> str:
    """å¾æ–‡å­—ä¸­æ“·å– JSON å…§å®¹çš„å€å¡Š (ä»¥ ```json ... ``` ç‚ºä¸»)"""
    pattern = r'```(?:json)?(.*)```'
    match = re.search(pattern, response, re.DOTALL)
    if match:
        json_str = match.group(1).strip()
        return json_str
    else:
        return response.strip()

# -------------------------------------------------
# ä»¥ä¸‹å€å¡Š: from openai import OpenAI æ–¹å¼æ‰€éœ€
#         åƒè€ƒæ‚¨çµ¦çš„ snippet
# -------------------------------------------------

def initialize_openai_client(api_key):
    """Initialize OpenAI client with the provided API key."""
    return OpenAI(api_key=api_key) if api_key else None

def load_image_base64(image):
    """Convert a PIL Image to Base64 encoding."""
    buffer = io.BytesIO()
    # è‹¥ image.format ä¸å­˜åœ¨ï¼Œå¯æ‰‹å‹•æŒ‡å®š PNG
    image.save(buffer, format=image.format if image.format else "PNG")
    return base64.b64encode(buffer.getvalue()).decode('utf-8')

def add_user_image(image):
    """Add an image message to st.session_state.messages (compat with streaming logic)."""
    img_base64 = load_image_base64(image)
    # åŠ åˆ° messages æœ«å°¾
    st.session_state.messages.append({
        "role": "user",
        "content": [
            {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{img_base64}"}}
        ]
    })

def reset_session_messages():
    """Clear conversation history from the session."""
    if "messages" in st.session_state:
        st.session_state.pop("messages")

def stream_llm_response(client, model_params):
    """
    ä»¥ for-chunk æ–¹å¼ä¸²æµå›å‚³æ–‡å­—ã€‚
    åƒè€ƒæ‚¨çµ¦çš„ snippet: client.chat.completions.create(...)
    """
    for chunk in client.chat.completions.create(
            model=model_params.get("model", "gpt-4o"),
            messages=st.session_state.messages,
            temperature=model_params.get("temperature", 0.3),
            max_tokens=4096,
            stream=True):
        chunk_text = chunk.choices[0].delta.content or ""
        yield chunk_text

# -------------------------------------------------
# åˆä½µä¸»ç¨‹å¼ main()
# -------------------------------------------------
def main():
    st.set_page_config(page_title="Chatbot + Data Analysis + StreamingImage", 
                       page_icon="ğŸ¤–", 
                       layout="wide")
    st.title("ğŸ¤– Chatbot + ğŸ“Š Data Analysis + ğŸ§  Memory + ğŸ–‹ï¸ Editor + (OpenAI streaming for only-image)")

    # --- åˆå§‹åŒ– session state è®Šæ•¸ ---
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "ace_code" not in st.session_state:
        st.session_state.ace_code = ""
    if "editor_location" not in st.session_state:
        st.session_state.editor_location = "Main"
    if "uploaded_file_path" not in st.session_state:
        st.session_state.uploaded_file_path = None
    if "uploaded_image_path" not in st.session_state:
        st.session_state.uploaded_image_path = None
    if "image_base64" not in st.session_state:
        st.session_state.image_base64 = None
    if "debug_mode" not in st.session_state:
        st.session_state.debug_mode = False
    if "deep_analysis_mode" not in st.session_state:
        st.session_state.deep_analysis_mode = False
    if "second_response" not in st.session_state:
        st.session_state.second_response = ""
    if "third_response" not in st.session_state:
        st.session_state.third_response = ""
    if "deep_analysis_image" not in st.session_state:
        st.session_state.deep_analysis_image = None

    with st.sidebar:
        st.subheader("ğŸ”’ Enter Your API Key")
        default_api_key = os.getenv("OPENAI_API_KEY", "")
        api_key = st.text_input("OpenAI API Key", value=default_api_key, type="password")

        # -- LangChain ChatOpenAI åˆå§‹åŒ– (b_v2)
        selected_model = st.selectbox("é¸æ“‡æ¨¡å‹ (for b_v2 logic):", OPENAI_MODELS, index=0)
        if "conversation" not in st.session_state:
            if api_key:
                st.session_state.chat_model = initialize_client(api_key, selected_model)
                st.session_state.memory = ConversationBufferMemory()
                st.session_state.conversation = ConversationChain(
                    llm=st.session_state.chat_model,
                    memory=st.session_state.memory
                )
            else:
                st.warning("â¬…ï¸ è«‹è¼¸å…¥ API Key ä»¥åˆå§‹åŒ–èŠå¤©æ©Ÿå™¨äºº (LangChain).")
                return

        st.session_state.debug_mode = st.checkbox("Debug Mode", value=False)
        st.session_state.deep_analysis_mode = st.checkbox("æ·±åº¦åˆ†ææ¨¡å¼", value=False)

        # -- openai client (from openai import OpenAI)
        #    ç”¨æ–¼ã€Œåªæœ‰åœ–ç‰‡æ™‚ã€çš„ streaming chat
        if "client_4o" not in st.session_state:
            st.session_state.client_4o = initialize_openai_client(api_key)
        else:
            # è‹¥å¾ŒçºŒè¦æ›´æ–°key
            st.session_state.client_4o = initialize_openai_client(api_key)

        if st.button("ğŸ—‘ï¸ Clear Memory (b_v2 & messages)"):
            st.session_state.memory.clear()
            st.session_state.messages = []
            st.session_state.ace_code = ""
            st.session_state.uploaded_file_path = None
            st.session_state.uploaded_image_path = None
            st.session_state.image_base64 = None
            st.session_state.deep_analysis_mode = False
            st.session_state.second_response = ""
            st.session_state.third_response = ""
            st.session_state.deep_analysis_image = None
            st.success("Memory cleared!")

        st.subheader("ğŸ§  Memory State (LangChain b_v2)")
        if "memory" in st.session_state:
            memory_content = st.session_state.memory.load_memory_variables({})
            st.text_area("Current Memory", value=str(memory_content), height=200)

        # -- åœ–åƒä¸Šå‚³/æ‹ç…§ (4o snippet) (å¯ä»¥å’Œ b_v2 çš„åŠŸèƒ½å…±å­˜)
        st.write("### 4o: ä¸Šå‚³åœ–åƒæˆ–æ‹ç…§ (Streaming only-image scenario)")
        uploaded_img_4o = st.file_uploader("é¸æ“‡ä¸€å¼µåœ–ç‰‡:", type=["png", "jpg", "jpeg"], key="4o_uploader")
        if uploaded_img_4o:
            img = Image.open(uploaded_img_4o)
            add_user_image(img)
            st.success("åœ–åƒå·²ä¸Šå‚³è‡³ messages!")

        camera_img = st.camera_input("æ‹ç…§")
        if camera_img:
            cimg = Image.open(camera_img)
            add_user_image(cimg)
            st.success("æ‹ç…§å·²æˆåŠŸï¼Œå·²åŠ å…¥messages!")

        # -- é‡ç½®å°è©± (4o snippet)
        st.button("ğŸ—‘ï¸ æ¸…é™¤å°è©± (stream messages)", on_click=reset_session_messages)

        # -- CSV ä¸Šå‚³ (b_v2)
        st.subheader("ğŸ“‚ Upload a CSV File (b_v2 style)")
        uploaded_file = st.file_uploader("Choose a CSV file:", type=["csv"], key="b_v2_csv")
        csv_data = None
        if uploaded_file:
            st.session_state.uploaded_file_path = save_uploaded_file(uploaded_file)
            debug_log(f"DEBUG: st.session_state.uploaded_file_path = {st.session_state.uploaded_file_path}")
            try:
                csv_data = pd.read_csv(st.session_state.uploaded_file_path)
                st.write("### Data Preview")
                st.dataframe(csv_data)
            except Exception as e:
                if st.session_state.debug_mode:
                    st.error(f"Error reading CSV: {e}")
                debug_log(f"[DEBUG] Error reading CSV: {e}")

        # -- åœ–ç‰‡ä¸Šå‚³ (b_v2)ï¼›å¯ä»¥èˆ‡ 4o snippet ä½µå­˜
        st.subheader("ğŸ–¼ï¸ Upload an Image (b_v2 style)")
        uploaded_image = st.file_uploader("Choose an image:", type=["png", "jpg", "jpeg"], key="b_v2_image")
        if uploaded_image:
            st.session_state.uploaded_image_path = save_uploaded_file(uploaded_image)
            debug_log(f"DEBUG: st.session_state.uploaded_image_path = {st.session_state.uploaded_image_path}")

            st.image(st.session_state.uploaded_image_path, caption="Uploaded Image Preview", use_column_width=True)
            try:
                with open(st.session_state.uploaded_image_path, "rb") as f:
                    img_bytes = f.read()
                st.session_state.image_base64 = base64.b64encode(img_bytes).decode("utf-8")
                debug_log("DEBUG: Image has been converted to base64.")
            except Exception as e:
                if st.session_state.debug_mode:
                    st.error(f"Error converting image to base64: {e}")
                debug_log(f"[DEBUG] Error converting image to base64: {e}")

        # -- Editor Location
        st.subheader("Editor Location")
        location = st.radio(
            "Choose where to display the editor:",
            ["Main", "Sidebar"],
            index=0 if st.session_state.editor_location == "Main" else 1
        )
        st.session_state.editor_location = location

    # ---- é¡¯ç¤ºå°è©±æ­·å² (messages) ----
    st.write("## Current Messages:")
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # é€å‰‡è¼¸å‡º messages
    for message in st.session_state.messages:
        role = message["role"]
        with st.chat_message(role):
            # message["content"] å¯èƒ½æ˜¯list( 4o snippet )æˆ–å–®ç´”string(b_v2)
            contents = message["content"]
            if isinstance(contents, list):
                # 4o snippet: contentæ˜¯list of dict
                for c in contents:
                    if c["type"] == "text":
                        st.write(c.get("text", ""))
                    elif c["type"] == "image_url":
                        st.image(c["image_url"].get("url", ""), caption="User's image")
            else:
                # b_v2: ç›´æ¥æ˜¯string
                st.write(contents)

            if "code" in message:  # b_v2: å¯èƒ½æœ‰ code
                st.code(message["code"], language="python")

    # ---- User input for b_v2 logic ----
    user_input = st.chat_input("b_v2 or 4o: Hi! Ask me anything ...")
    if user_input:
        # å…ˆæŠŠé€™æ¬¡ user_input åŠ å…¥å°è©±
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.write(user_input)

        with st.spinner("Thinking..."):
            try:
                debug_log(f"DEBUG: uploaded_file_path = {st.session_state.uploaded_file_path}")
                debug_log(f"DEBUG: uploaded_image_path = {st.session_state.uploaded_image_path}")

                # åˆ¤æ–·ã€Œåªæœ‰åœ–ç‰‡ä¸”æ²’æœ‰ CSVã€ => ä»£è¡¨ b_v2_image or 4o_uploader/camera æœ‰åœ–ï¼Œä½† CSV æ˜¯ None
                # ä½†æ˜¯ç¾åœ¨ messages å¯èƒ½ä¹Ÿæœ‰ 4o snippet çš„åœ–
                # æˆ‘å€‘ä»¥ b_v2 æ–¹å¼åˆ¤æ–·: st.session_state.uploaded_file_path is None => æ²’CSV
                # ä¸” (st.session_state.uploaded_image_path is not None or messagesè£¡é¢æœ‰ image_url)
                
                # ç°¡åŒ–: å¦‚æœ "uploaded_file_path" is None (æ²’csv) AND "uploaded_image_path" is not None => only image
                only_image = False
                if (st.session_state.uploaded_file_path is None) and (st.session_state.uploaded_image_path is not None):
                    only_image = True

                # å¦å¤–ä¸€ç¨®æª¢æŸ¥: messages ä¸­æ˜¯å¦å­˜åœ¨ image_url?
                # ä½†é€™å¯èƒ½æœƒèˆ‡ b_v2 ç›¸è¡ï¼Œå…ˆç”¨ä¸Šé¢ simpler method

                if only_image and st.session_state.client_4o is not None:
                    # æ”¹ç”¨ streaming approach (client_4o)

                    debug_log("DEBUG: Only Image scenario => using client.chat.completions.create streaming...")

                    # é€™è£¡ content å¯èƒ½æ˜¯æ–‡å­— + base64ï¼ˆè‹¥ b_v2 åœ–ç‰‡ï¼‰ï¼Œæˆ–è€… snippet ä¸­ user_image
                    # ä¸éæˆ‘å€‘å·²ç¶“æŠŠ user_input append äº† => messages
                    # é å‚™ streaming: model_params
                    model_params = {
                        "model": "gpt-4o",  # æˆ–å¯æ”¹æˆ selected_model
                        "temperature": 0.3
                    }
                    # ç›´æ¥å‘¼å« stream_llm_response
                    full_response = ""
                    with st.chat_message("assistant"):
                        stream_placeholder = st.empty()
                        try:
                            for chunk_text in stream_llm_response(st.session_state.client_4o, model_params):
                                full_response += chunk_text
                                stream_placeholder.markdown(full_response)
                        except Exception as e:
                            if st.session_state.debug_mode:
                                st.error(f"Streaming error: {e}")
                            debug_log(f"[DEBUG] Streaming error: {e}")

                    # å°‡ä¸²æµæœ€çµ‚çµæœå¯«å› messages
                    st.session_state.messages.append({"role": "assistant", "content": full_response})

                else:
                    # å…¶é¤˜æƒ…æ³ => èµ°èˆŠæœ‰ b_v2 JSON + LangChain logic
                    # ä¾‹å¦‚ => æœ‰ CSV æˆ–å®Œå…¨æ²’ä¸Šå‚³æª”æ¡ˆ
                    if st.session_state.uploaded_image_path and st.session_state.image_base64:
                        # [æƒ…å¢ƒ] æœ‰ä¸Šå‚³åœ–ç‰‡ + (ä¹Ÿè¨±CSV?? or not??) => èˆŠé‚è¼¯
                        prompt = f"User input: {user_input}\nHere is the image data in base64:\n{st.session_state.image_base64}..."
                    else:
                        if st.session_state.uploaded_file_path is not None:
                            try:
                                df_temp = pd.read_csv(st.session_state.uploaded_file_path)
                                csv_columns = ", ".join(df_temp.columns)
                            except Exception as e:
                                csv_columns = "ç„¡æ³•è®€å–æ¬„ä½"
                                if st.session_state.debug_mode:
                                    st.error(f"Error reading columns: {e}")
                                debug_log(f"[DEBUG] Error reading columns: {e}")
                        else:
                            csv_columns = "ç„¡ä¸Šå‚³æª”æ¡ˆ"

                        prompt = f"""Please respond with a JSON object in the format:
{{
    "content": "é€™æ˜¯æˆ‘çš„è§€å¯Ÿï¼š{{{{åˆ†æå…§å®¹}}}}",
    "code": "import pandas as pd\\nimport streamlit as st\\nimport matplotlib.pyplot as plt\\n# è®€å– CSV æª”æ¡ˆ (è«‹ç›´æ¥ä½¿ç”¨ st.session_state.uploaded_file_path è®Šæ•¸)\\ndata = pd.read_csv(st.session_state.uploaded_file_path)\\n\\n# åœ¨é€™è£¡åŠ å…¥ä½ è¦çš„ç¹ªåœ–æˆ–åˆ†æé‚è¼¯\\n\\n# ä¾‹å¦‚ä½¿ç”¨ st.pyplot() ä¾†é¡¯ç¤ºåœ–è¡¨:\\n# fig, ax = plt.subplots()\\n# ax.scatter(data['colA'], data['colB'])\\n# st.pyplot(fig)\\n"
}}
Important:
1) Must use st.session_state.uploaded_file_path as the CSV path (instead of a hardcoded path)
2) Must use st.pyplot() to display any matplotlib figure
3) Return only valid JSON (escape any special characters if needed)

Based on the request: {user_input}.
Available columns: {csv_columns}.
"""
                        if csv_columns == "ç„¡ä¸Šå‚³æª”æ¡ˆ":
                            prompt = f"è«‹å…¨éƒ¨ä»¥ç¹é«”ä¸­æ–‡å›ç­”æ­¤å•é¡Œï¼š{user_input}"

                    debug_log(f"DEBUG: Prompt => {prompt}")

                    # ç”¨LangChain conversation
                    raw_response = st.session_state.conversation.run(prompt)
                    if st.session_state.debug_mode:
                        st.write("Model raw response:", raw_response)
                    debug_log(f"[DEBUG] Model raw response => {raw_response}")

                    # å˜—è©¦è§£æ JSON
                    json_str = extract_json_block(raw_response)
                    try:
                        response_json = json.loads(json_str)
                    except Exception as e:
                        debug_log(f"json.loads parsing error: {e}")
                        debug_error(f"json.loads parsing error: {e}")
                        response_json = {"content": json_str, "code": ""}

                    content = response_json.get("content", "é€™æ˜¯æˆ‘çš„åˆ†æï¼š")
                    st.session_state.messages.append({"role": "assistant", "content": content})
                    with st.chat_message("assistant"):
                        st.write(content)

                    code = response_json.get("code", "")
                    if code:
                        st.session_state.messages.append({"role": "assistant", "code": code})
                        with st.chat_message("assistant"):
                            st.code(code, language="python")
                        st.session_state.ace_code = code

                    # è‹¥æ·±åº¦åˆ†æ => åŸ·è¡Œä¸¦å†é€ GPT-4o åšäºŒéš/ä¸‰éšå›è¦†
                    if st.session_state.deep_analysis_mode and code:
                        st.write("### [æ·±åº¦åˆ†æ] è‡ªå‹•åŸ·è¡Œç”¢ç”Ÿçš„ç¨‹å¼ç¢¼ä¸¦å°‡åœ–è¡¨é€è‡³ GPT-4o è§£æ...")

                        global_vars = {
                            "uploaded_file_path": st.session_state.uploaded_file_path,
                            "uploaded_image_path": st.session_state.uploaded_image_path,
                        }
                        exec_result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                        st.write("#### Execution Result")
                        st.text(exec_result)

                        fig = plt.gcf()
                        buf = io.BytesIO()
                        fig.savefig(buf, format="png")
                        buf.seek(0)
                        chart_base64 = base64.b64encode(buf.read()).decode("utf-8")
                        st.session_state.deep_analysis_image = chart_base64

                        # ç¬¬äºŒéšæ®µ
                        deep_model = ChatOpenAI(
                            model="gpt-4o",
                            temperature=0.5,
                            openai_api_key=api_key
                        ) if api_key else None
                        if deep_model:
                            prompt_2 = f"""
é€™æ˜¯ä¸€å¼µæˆ‘å¾å‰›æ‰çš„ç¨‹å¼ç¢¼ä¸­ç”¢ç”Ÿçš„åœ–è¡¨ï¼Œä»¥ä¸‹æ˜¯åœ–è¡¨çš„base64ç·¨ç¢¼ï¼š
{chart_base64[:300]}...

è«‹ä½ ç‚ºæˆ‘é€²è¡Œé€²ä¸€æ­¥çš„åˆ†æï¼Œè§£é‡‹é€™å¼µåœ–è¡¨å¯èƒ½ä»£è¡¨ä»€éº¼æ¨£çš„æ•¸æ“šè¶¨å‹¢æˆ–è§€å¯Ÿã€‚
"""
                            debug_log(f"DEBUG: Deep Analysis Prompt => {prompt_2}")
                            second_raw_response = deep_model.call_as_llm(prompt_2)
                            st.session_state.second_response = second_raw_response

                            st.write("#### [æ·±åº¦åˆ†æ] åœ–è¡¨è§£æçµæœ (ç¬¬äºŒæ¬¡å›è¦†) :")
                            st.write(second_raw_response)

                            # ç¬¬ä¸‰éšæ®µ
                            final_model = ChatOpenAI(
                                model="gpt-4o",
                                temperature=0.5,
                                openai_api_key=api_key
                            ) if api_key else None
                            if final_model:
                                prompt_3 = f"""
ç¬¬ä¸€éšæ®µå›è¦†å…§å®¹ï¼š{content}
ç¬¬äºŒéšæ®µåœ–è¡¨è§£æå…§å®¹ï¼š{second_raw_response}

è«‹ä½ å¹«æˆ‘æŠŠä»¥ä¸Šå…©éšæ®µçš„å…§å®¹å¥½å¥½åšä¸€å€‹æ–‡å­—ç¸½çµï¼Œä¸¦æä¾›é¡å¤–çš„å»ºè­°æˆ–è¦‹è§£ã€‚
"""
                                debug_log(f"DEBUG: Final Summary Prompt => {prompt_3}")
                                third_raw_response = final_model.call_as_llm(prompt_3)
                                st.session_state.third_response = third_raw_response

                                st.write("#### [æ·±åº¦åˆ†æ] çµè«– (ç¬¬ä¸‰æ¬¡å›è¦†) :")
                                st.write(third_raw_response)

                                st.write("#### [æ·±åº¦åˆ†æ] åœ–è¡¨ï¼š")
                                img_data = base64.b64decode(st.session_state.deep_analysis_image)
                                st.image(img_data, caption="æ·±åº¦åˆ†æç”¢ç”Ÿçš„åœ–è¡¨", use_column_width=True)

            except Exception as e:
                if st.session_state.debug_mode:
                    st.error(f"An error occurred: {e}")
                debug_log(f"[DEBUG] An error occurred: {e}")

    # --- Debug logs ---
    debug_log(f"DEBUG: editor_location = {st.session_state.editor_location}")
    debug_log(f"DEBUG: final st.session_state.uploaded_file_path = {st.session_state.uploaded_file_path}")
    debug_log(f"DEBUG: final st.session_state.uploaded_image_path = {st.session_state.uploaded_image_path}")

    # --- é¡¯ç¤º Code Editor ---
    if st.session_state.editor_location == "Main":
        with st.expander("ğŸ–‹ï¸ Persistent Code Editor (Main)", expanded=False):
            edited_code = st_ace(
                value=st.session_state.ace_code,
                language="python",
                theme="monokai",
                height=300,
                key="persistent_editor_main"
            )
            if edited_code != st.session_state.ace_code:
                st.session_state.ace_code = edited_code

            if st.button("â–¶ï¸ Execute Code", key="execute_code_main"):
                global_vars = {
                    "uploaded_file_path": st.session_state.uploaded_file_path,
                    "uploaded_image_path": st.session_state.uploaded_image_path,
                }
                debug_log(f"DEBUG: executing code with uploaded_file_path = {st.session_state.uploaded_file_path}")
                debug_log(f"DEBUG: executing code with uploaded_image_path = {st.session_state.uploaded_image_path}")

                result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                st.write("### Execution Result")
                st.text(result)
    else:
        with st.sidebar.expander("ğŸ–‹ï¸ Persistent Code Editor (Sidebar)", expanded=False):
            edited_code = st_ace(
                value=st.session_state.ace_code,
                language="python",
                theme="monokai",
                height=300,
                key="persistent_editor_sidebar"
            )
            if edited_code != st.session_state.ace_code:
                st.session_state.ace_code = edited_code

            if st.button("â–¶ï¸ Execute Code", key="execute_code_sidebar"):
                global_vars = {
                    "uploaded_file_path": st.session_state.uploaded_file_path,
                    "uploaded_image_path": st.session_state.uploaded_image_path,
                }
                debug_log(f"DEBUG: executing code with uploaded_file_path = {st.session_state.uploaded_file_path}")
                debug_log(f"DEBUG: executing code with uploaded_image_path = {st.session_state.uploaded_image_path}")

                result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                st.write("### Execution Result")
                st.text(result)

# --- ç¨‹å¼å…¥å£ ---
if __name__ == "__main__":
    main()
