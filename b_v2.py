import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from io import BytesIO
import json
import time
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain.chat_models import ChatOpenAI
import dotenv
import os
from streamlit_ace import st_ace
import traceback

# --- Initialize and Settings ---
dotenv.load_dotenv()

def initialize_client(api_key):
    """Initialize OpenAI client with the provided API key."""
    return ChatOpenAI(model="gpt-4-turbo", temperature=0.5, openai_api_key=api_key) if api_key else None

def execute_code(code):
    """Execute the given Python code and capture output."""
    try:
        exec_globals = {}
        exec(code, exec_globals)
        return "Code executed successfully. Output: " + str(exec_globals.get("output", "(No output returned)"))
    except Exception as e:
        return f"Error executing code:\n{traceback.format_exc()}"

def main():
    # è¨­å®š Streamlit é é¢æ¨™é¡Œèˆ‡é…ç½®
    st.set_page_config(page_title="Chatbot + Data Analysis", page_icon="ğŸ¤–", layout="centered")
    st.title("ğŸ¤– Chatbot + ğŸ“Š Data Analysis + ğŸ§  Memory + ğŸ–‹ï¸ Canvas")

    with st.sidebar:
        st.subheader("ğŸ”’ Enter Your API Key")
        api_key = st.text_input("OpenAI API Key", type="password")

        # åˆå§‹åŒ– LangChain èˆ‡è¨˜æ†¶
        if "conversation" not in st.session_state:
            if api_key:
                st.session_state.chat_model = initialize_client(api_key)
                st.session_state.memory = ConversationBufferMemory()
                st.session_state.conversation = ConversationChain(
                    llm=st.session_state.chat_model,
                    memory=st.session_state.memory
                )
            else:
                st.warning("â¬…ï¸ è«‹è¼¸å…¥ API Key ä»¥åˆå§‹åŒ–èŠå¤©æ©Ÿå™¨äººã€‚")
                return

        # æ¸…é™¤è¨˜æ†¶
        if st.button("ğŸ—‘ï¸ Clear Memory"):
            st.session_state.memory.clear()
            st.session_state.messages = []
            st.success("Memory cleared!")

        # é¡¯ç¤ºè¨˜æ†¶ç‹€æ…‹
        st.subheader("ğŸ§  Memory State")
        if "memory" in st.session_state:
            memory_content = st.session_state.memory.load_memory_variables({})
            st.text_area("Current Memory", value=str(memory_content), height=200)

        # ä¸Šå‚³ CSV
        st.subheader("ğŸ“‚ Upload a CSV File")
        uploaded_file = st.file_uploader("Choose a CSV file:", type=["csv"])
        csv_data = None
        if uploaded_file:
            csv_data = pd.read_csv(uploaded_file)
            st.write("### Data Preview")
            st.dataframe(csv_data)

    # å„²å­˜å°è©±è¨Šæ¯
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # é¡¯ç¤ºå…ˆå‰ç”Ÿæˆçš„è¨Šæ¯ï¼ˆè§’è‰²å°è©±ï¼‰
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if "content" in message:
                st.write(message["content"])
            if "code" in message:
                st.code(message["code"], language="python")

    # ä½¿ç”¨è€…è¼¸å…¥
    user_input = st.chat_input("Hi! Ask me anything...")
    if user_input:
        # è¨˜éŒ„ä½¿ç”¨è€…è¨Šæ¯
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.write(user_input)

        # ç”¢ç”Ÿå›è¦†
        with st.spinner("Thinking..."):
            try:
                if csv_data is not None:
                    # å–å¾— CSV æ¬„ä½åç¨±
                    csv_columns = ", ".join(csv_data.columns)
                    # ä½¿ç”¨é›™å¤§æ‹¬è™Ÿä»¥é¡¯ç¤ºå¤§æ‹¬è™Ÿå­—é¢é‡
                    prompt = f"""Please respond with a JSON object in the format:
{{
    "content": "æ ¹æ“š {csv_columns} çš„æ•¸æ“šåˆ†æï¼Œé€™æ˜¯æˆ‘çš„è§€å¯Ÿï¼š{{{{åˆ†æå…§å®¹}}}}",
    "code": ""
}}
Based on the request: {user_input}.
Available columns: {csv_columns}.
"""
                else:
                    prompt = f"è«‹å…¨éƒ¨ä»¥ç¹é«”ä¸­æ–‡å›ç­”æ­¤å•é¡Œï¼š{user_input}"

                # å‘¼å« LangChain
                response = st.session_state.conversation.run(prompt)

                # ç‚ºäº† debugï¼Œå¯ä»¥å…ˆæª¢æŸ¥åŸå§‹è¼¸å‡º
                st.write("Model raw response:", response)

                # å˜—è©¦è½‰æˆ JSON æ ¼å¼
                try:
                    response_json = json.loads(response)
                except Exception as e:
                    st.error(f"json.loads parsing error: {e}")
                    # å¦‚æœè§£æå¤±æ•—ï¼Œfallback ç‚ºæœ€ç°¡å–®çš„æ ¼å¼
                    response_json = {"content": response, "code": ""}

                # é¡¯ç¤ºå›è¦†çš„æ–‡å­—å…§å®¹
                content = response_json.get("content", "é€™æ˜¯æˆ‘çš„åˆ†æï¼š")
                st.session_state.messages.append({"role": "assistant", "content": content})
                with st.chat_message("assistant"):
                    st.write(content)

                # å¦‚æœæœ‰ç¨‹å¼ç¢¼ï¼Œå‰‡é¡¯ç¤º
                code = response_json.get("code", "")
                if code:
                    st.session_state.messages.append({"role": "assistant", "code": code})
                    with st.chat_message("assistant"):
                        st.code(code, language="python")

                    # é¡¯ç¤ºå¯ç·¨è¼¯çš„ ACE Editor
                    st.write("### ğŸ–‹ï¸ Edit and Execute Code")
                    edited_code = st_ace(value=code, language="python", theme="monokai", height=300)

                    # åŸ·è¡ŒæŒ‰éˆ•
                    if st.button("â–¶ï¸ Execute Code"):
                        result = execute_code(edited_code)
                        st.write("### Execution Result")
                        st.text(result)

            except Exception as e:
                st.error(f"An error occurred: {e}")

if __name__ == "__main__":
    main()
