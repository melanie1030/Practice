import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import json
import traceback
import re
import os
import dotenv
import base64
import io

# --------------- (ä¾†è‡ª4o_image_handleçš„import) ---------------
from PIL import Image
from audio_recorder_streamlit import audio_recorder
import random

# --------------- (LangChainç›¸é—œ) ---------------
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain.chat_models import ChatOpenAI

# --- dotenv åˆå§‹åŒ– ---
dotenv.load_dotenv()

# === å…¨åŸŸè¨­å®š ===
UPLOAD_DIR = "uploaded_files"
OPENAI_MODELS = ["gpt-4o"]  # ä»¥4oä½œç‚ºå¯é¸æ¨¡å‹

# -------------------------------------------
# ä»¥ä¸‹å€å¡Šç‚º b_v2.py åŸæœ‰çš„åŠŸèƒ½ & å‡½å¼
# -------------------------------------------

def debug_log(msg):
    """è‹¥ debug_mode=True å‰‡åœ¨ç•«é¢èˆ‡consoleå°å‡ºæç¤º"""
    if st.session_state.get("debug_mode", False):
        st.write(msg)
        print(msg)

def debug_error(msg):
    """è‹¥ debug_mode=True å‰‡åœ¨ç•«é¢èˆ‡consoleå°å‡ºéŒ¯èª¤è¨Šæ¯"""
    if st.session_state.get("debug_mode", False):
        st.error(msg)
        print(msg)

def initialize_client(api_key, model_name):
    """
    ç”± b_v2 åŸå…ˆä½¿ç”¨çš„ LangChain ChatOpenAIã€‚
    ä¸è¦ç§»é™¤æ­¤å‡½å¼ï¼Œä»¥å…¼å®¹åŸæœ‰å°è©±æµç¨‹ (ConversationChain)ã€‚
    """
    return ChatOpenAI(
        model=model_name,
        temperature=0.5,
        openai_api_key=api_key
    ) if api_key else None

def save_uploaded_file(uploaded_file):
    """å°‡ä¸Šå‚³æª”æ¡ˆå­˜è‡³æŒ‡å®šè³‡æ–™å¤¾"""
    if not os.path.exists(UPLOAD_DIR):
        os.makedirs(UPLOAD_DIR)
    file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)

    debug_log(f"DEBUG: saving file to {file_path}")
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    debug_log(f"DEBUG: files in {UPLOAD_DIR}: {os.listdir(UPLOAD_DIR)}")
    return file_path

def execute_code(code, global_vars=None):
    """åŸ·è¡Œä½¿ç”¨è€…ç”¢ç”Ÿçš„Pythonç¨‹å¼ç¢¼"""
    try:
        exec_globals = global_vars if global_vars else {}
        debug_log("DEBUG: Ready to exec the following code:")
        if st.session_state.get("debug_mode", False):
            st.code(code, language="python")

        debug_log("[DEBUG] Exec code with global_vars: " + str(list(exec_globals.keys())))
        exec(code, exec_globals)
        return "Code executed successfully. Output: " + str(exec_globals.get("output", "(No output returned)"))
    except Exception as e:
        error_msg = f"Error executing code:\n{traceback.format_exc()}"
        debug_log("[DEBUG] Execution error: " + error_msg)
        if st.session_state.get("debug_mode", False):
            return error_msg
        else:
            return "Error executing code (hidden in non-debug mode)."

def extract_json_block(response: str) -> str:
    """å¾æ–‡å­—ä¸­æ“·å– JSON å…§å®¹çš„å€å¡Š (ä»¥ ```json ... ``` ç‚ºä¸»)"""
    pattern = r'```(?:json)?(.*)```'
    match = re.search(pattern, response, re.DOTALL)
    if match:
        json_str = match.group(1).strip()
        return json_str
    else:
        return response.strip()

# -------------------------------------------
# ä»¥ä¸‹å€å¡Šç‚º 4o_image_handle.py ä¸»è¦åŠŸèƒ½ & å‡½å¼
# -------------------------------------------

import openai  # æ³¨æ„ï¼šè‹¥ç„¡æ³•ä½¿ç”¨ `from openai import OpenAI`ï¼Œå¯ç›´æ¥ `import openai`
               # ä»¥ä¸‹ä»¥ openai å®˜æ–¹å¥—ä»¶ç‚ºä¾‹ï¼Œå¦‚æœ‰å®¢è£½ OpenAI(api_key=...) ç‰©ä»¶æ™‚ï¼Œéœ€è‡ªè¡Œæ”¹å¯«

def initialize_openai_client(api_key):
    """
    ç”± 4o_image_handle.py ä¸­çš„ initialize_client(api_key) æ”¹å¯«è€Œä¾†ã€‚
    ä¸ç§»é™¤ã€‚æ­¤è™•ç›´æ¥çµ¦ openai.api_key ã€‚
    """
    if api_key:
        openai.api_key = api_key
    else:
        openai.api_key = None

def load_image_base64(image: Image.Image):
    """å°‡ PIL Image è½‰æ›ç‚º base64 å­—ä¸²"""
    buffer = io.BytesIO()
    # è‹¥ä¸ç¢ºå®š image.formatï¼Œå¯è¦–æƒ…æ³æ‰‹å‹•æŒ‡å®šï¼Œå¦‚ PNG
    image.save(buffer, format=image.format if image.format else "PNG")
    buffer.seek(0)
    return base64.b64encode(buffer.getvalue()).decode('utf-8')

def add_user_image(image):
    """
    åœ¨ 4o_image_handle.py ä¸­ï¼ŒæœƒæŠŠåœ–åƒåŠ åˆ° session_state.messages ä¾› Chat ä½¿ç”¨ã€‚
    ä½† b_v2.py èˆ‡æ­¤é‚è¼¯ä¸åŒã€‚æ­¤è™•å…ˆä¿ç•™ä»¥ä¾¿åœ¨åˆä½µå¾Œå¯åƒè€ƒã€‚
    """
    img_base64 = load_image_base64(image)
    if "stream_messages" not in st.session_state:
        st.session_state.stream_messages = []
    st.session_state.stream_messages.append({
        "role": "user",
        "content": [
            {
                "type": "image_url", 
                "image_url": {"url": f"data:image/png;base64,{img_base64}"}
            }
        ]
    })

def reset_session_messages():
    """æ¸…é™¤å°è©±è¨Šæ¯ (é‡å° 4o_image_handle çš„å°è©±æµ)"""
    if "stream_messages" in st.session_state:
        st.session_state.pop("stream_messages")

def stream_llm_response(messages, model="gpt-4o", temperature=0.3):
    """
    åƒè€ƒ 4o_image_handle.pyï¼šä½¿ç”¨ openai.ChatCompletion.create() + stream=True
    é€²è¡Œä¸²æµè¼¸å‡ºã€‚
    é€™èˆ‡ b_v2.py ç”¨ LangChain ChatOpenAI åŸ·è¡Œå°è©±ä¸åŒï¼Œæ˜¯å…©å¥—æ©Ÿåˆ¶ã€‚
    """
    try:
        completion = openai.ChatCompletion.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=4096,
            stream=True
        )
        for chunk in completion:
            chunk_text = chunk["choices"][0].get("delta", {}).get("content", "")
            if chunk_text:
                yield chunk_text
    except Exception as e:
        yield f"ã€ä¸²æµç™¼ç”ŸéŒ¯èª¤ã€‘{str(e)}"

# -------------------------------------------
# ä¸Šè¿°å…©å¤§å€å¡Šç‚º b_v2.py & 4o_image_handle.py çš„å‡½å¼åº«
# ä»¥ä¸‹é–‹å§‹æ’°å¯«ä¸€å€‹ã€Œåˆä½µå¾Œçš„ main()ã€ï¼ŒåŒæ™‚ä¿ç•™ b_v2.py åŸæœ¬çš„ä¸»ä»‹é¢
# ä¸¦å¢æ·» 4o_image_handle.py çš„åŠŸèƒ½ (å¦‚ä¸²æµã€æ‹ç…§ã€éŒ„éŸ³ç­‰)ã€‚
# -------------------------------------------

def main():
    # === ä¾ b_v2.py è¨­ç½®é¦–é åŸºæœ¬é…ç½® ===
    st.set_page_config(page_title="Chatbot + Data Analysis + 4o Image+Audio", 
                       page_icon="ğŸ¤–", 
                       layout="wide")

    st.title("ğŸ¤– Chatbot + ğŸ“Š Data Analysis + ğŸ§  Memory + ğŸ–‹ï¸ Canvas + (4o Streaming / Image / Audio)")

    # -------------- åˆå§‹åŒ– session_state è®Šæ•¸ --------------
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "ace_code" not in st.session_state:
        st.session_state.ace_code = ""
    if "editor_location" not in st.session_state:
        st.session_state.editor_location = "Main"
    if "uploaded_file_path" not in st.session_state:
        st.session_state.uploaded_file_path = None
    if "uploaded_image_path" not in st.session_state:
        st.session_state.uploaded_image_path = None
    if "image_base64" not in st.session_state:
        st.session_state.image_base64 = None
    if "debug_mode" not in st.session_state:
        st.session_state.debug_mode = False
    if "deep_analysis_mode" not in st.session_state:
        st.session_state.deep_analysis_mode = False
    if "second_response" not in st.session_state:
        st.session_state.second_response = ""
    if "third_response" not in st.session_state:
        st.session_state.third_response = ""
    if "deep_analysis_image" not in st.session_state:
        st.session_state.deep_analysis_image = None
    
    # 4o_image_handle çš„ stream_messages
    if "stream_messages" not in st.session_state:
        st.session_state.stream_messages = []

    # --- å´é‚Šæ¬„ ---
    with st.sidebar:
        st.subheader("ğŸ”’ Enter Your API Key")
        api_key = st.text_input("OpenAI API Key", type="password")

        # 4o_image_handle & b_v2 çš†éœ€è¦ API Key
        # initialize_openai_client å…ˆè¨­å®š openai.api_key
        initialize_openai_client(api_key)

        # b_v2.py ç”¨æ–¼ langchain ChatOpenAI
        selected_model = st.selectbox("é¸æ“‡æ¨¡å‹ (LangChain):", OPENAI_MODELS, index=0)

        st.session_state.debug_mode = st.checkbox("Debug Mode", value=False)
        st.session_state.deep_analysis_mode = st.checkbox("æ·±åº¦åˆ†ææ¨¡å¼", value=False)

        # è‹¥å°šæœªæœ‰ conversation (LangChain)
        if "conversation" not in st.session_state:
            if api_key:
                st.session_state.chat_model = initialize_client(api_key, selected_model)
                st.session_state.memory = ConversationBufferMemory()
                st.session_state.conversation = ConversationChain(
                    llm=st.session_state.chat_model,
                    memory=st.session_state.memory
                )
            else:
                st.warning("â¬…ï¸ è«‹è¼¸å…¥ API Key ä»¥åˆå§‹åŒ–èŠå¤©æ©Ÿå™¨äººã€‚")

        if st.session_state.debug_mode:
            debug_log(f"DEBUG: Currently using model => {selected_model}")

        if st.button("ğŸ—‘ï¸ Clear Memory (b_v2)"):
            # åªæ¸…é™¤ b_v2 çš„ Memory
            st.session_state.memory.clear()
            st.session_state.messages = []
            st.session_state.ace_code = ""
            st.session_state.uploaded_file_path = None
            st.session_state.uploaded_image_path = None
            st.session_state.image_base64 = None
            st.session_state.deep_analysis_mode = False
            st.session_state.second_response = ""
            st.session_state.third_response = ""
            st.session_state.deep_analysis_image = None
            st.success("Memory cleared for b_v2 main chat!")
        
        # 4o_image_handle çš„ stream_messages æ¸…é™¤
        if st.button("ğŸ—‘ï¸ Clear Stream Messages (4o)"):
            reset_session_messages()
            st.success("Stream messages cleared for 4o approach!")

        st.subheader("ğŸ§  Memory State (b_v2)")
        if "memory" in st.session_state:
            memory_content = st.session_state.memory.load_memory_variables({})
            st.text_area("Current Memory (LangChain)", value=str(memory_content), height=200)

        # === CSV ä¸Šå‚³åŠŸèƒ½ (b_v2) ===
        st.subheader("ğŸ“‚ Upload a CSV File")
        uploaded_file = st.file_uploader("Choose a CSV file:", type=["csv"])
        csv_data = None
        if uploaded_file:
            st.session_state.uploaded_file_path = save_uploaded_file(uploaded_file)
            debug_log(f"DEBUG: st.session_state.uploaded_file_path = {st.session_state.uploaded_file_path}")
            try:
                csv_data = pd.read_csv(st.session_state.uploaded_file_path)
                st.write("### Data Preview")
                st.dataframe(csv_data)
            except Exception as e:
                if st.session_state.debug_mode:
                    st.error(f"Error reading CSV: {e}")
                debug_log(f"[DEBUG] Error reading CSV: {e}")

        # === åœ–ç‰‡ä¸Šå‚³ (b_v2) ===
        st.subheader("ğŸ–¼ï¸ Upload an Image (b_v2)")
        uploaded_image = st.file_uploader("Choose an image:", type=["png", "jpg", "jpeg"])
        if uploaded_image:
            st.session_state.uploaded_image_path = save_uploaded_file(uploaded_image)
            debug_log(f"DEBUG: st.session_state.uploaded_image_path = {st.session_state.uploaded_image_path}")

            st.image(st.session_state.uploaded_image_path, caption="Uploaded Image Preview", use_column_width=True)
            try:
                with open(st.session_state.uploaded_image_path, "rb") as f:
                    img_bytes = f.read()
                st.session_state.image_base64 = base64.b64encode(img_bytes).decode("utf-8")
                debug_log("DEBUG: Image has been converted to base64.")
            except Exception as e:
                if st.session_state.debug_mode:
                    st.error(f"Error converting image to base64: {e}")
                debug_log(f"[DEBUG] Error converting image to base64: {e}")

        # === 4o_image_handle.py ç›¸é—œï¼šåœ–åƒä¸Šå‚³ & ç›¸æ©Ÿæ‹ç…§ & éŸ³è¨ŠéŒ„è£½ ===
        st.subheader("4o: ä¸Šå‚³åœ–åƒ / æ‹ç…§ / éŒ„éŸ³ï¼ˆä¸²æµå›æ‡‰ï¼‰")

        # ç›¸æ©Ÿæ‹ç…§
        camera_img = st.camera_input("æ‹ç…§")
        if camera_img:
            cam_image = Image.open(camera_img)
            add_user_image(cam_image)
            st.success("æ‹ç…§å·²æˆåŠŸä¸¦åŠ åˆ° stream_messages!")

        # åœ–åƒä¸Šå‚³ (ç¨ç«‹æ–¼ b_v2 åŸæœ¬çš„)
        uploaded_img_4o = st.file_uploader("4o è¿½åŠ åœ–ç‰‡:", type=["png", "jpg", "jpeg"], key="4o_uploader")
        if uploaded_img_4o:
            up_image_4o = Image.open(uploaded_img_4o)
            add_user_image(up_image_4o)
            st.success("åœ–åƒå·²ä¸Šå‚³ä¸¦åŠ åˆ° stream_messages!")

        # éŸ³è¨ŠéŒ„è£½
        st.write("### éŒ„è£½éŸ³è¨Šä¸¦ä¸Šå‚³ (demo)")
        audio_data = audio_recorder()
        if audio_data is not None:
            st.success("éŒ„éŸ³å®Œæˆï¼(ç›®å‰æœªè‡ªå‹•åŠ å…¥å°è©±ï¼Œå¦‚éœ€å¯è‡ªè¡Œå®¢è£½åŒ–è™•ç†)")
            # é€™é‚Šå¯è‡ªè¡Œæ±ºå®šè¦å¦‚ä½•æŠŠéŸ³è¨Šè³‡æ–™é€åˆ° GPT-4o
            # ä¾‹å¦‚å…ˆåŠ åˆ° session_state.stream_messagesï¼Œæˆ–é€é openai çš„èªéŸ³API è½‰æ–‡å­—ã€‚
            # é€™é‚Šåƒ…ç¤ºç¯„é¡¯ç¤ºå·²éŒ„éŸ³ã€‚

        st.subheader("Editor Location (b_v2)")  # ä¿ç•™ b_v2 æ—¢æœ‰çš„ Editor Location
        location = st.radio(
            "Choose where to display the editor:",
            ["Main", "Sidebar"],
            index=0 if st.session_state.editor_location == "Main" else 1
        )
        st.session_state.editor_location = location

    # ----------------
    # (b_v2) é¡¯ç¤ºã€Œä¸»è¦å°è©±è¨˜éŒ„ã€ï¼šst.session_state.messages
    # ----------------
    st.write("## b_v2 ä¸»å°è©±å€ (LangChain ConversationChain)")
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if "content" in message:
                st.write(message["content"])
            if "code" in message:
                st.code(message["code"], language="python")

    # --- b_v2 çš„ç”¨æˆ¶è¼¸å…¥ ---
    user_input = st.chat_input("b_v2: Hi! Ask me anything (LangChain conversation)...")
    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.write(user_input)

        with st.spinner("Thinking..."):
            if not api_key:
                st.warning("å°šæœªå¡«å…¥ API Keyï¼Œç„¡æ³•ä½¿ç”¨ b_v2 çš„å°è©±åŠŸèƒ½ã€‚")
            else:
                try:
                    debug_log(f"DEBUG: Currently st.session_state.uploaded_file_path = {st.session_state.uploaded_file_path}")
                    debug_log(f"DEBUG: Currently st.session_state.uploaded_image_path = {st.session_state.uploaded_image_path}")

                    # æº–å‚™è¦ä¸Ÿçµ¦ GPT-4 (LangChain) çš„ prompt
                    if st.session_state.uploaded_image_path is not None and st.session_state.image_base64:
                        # [æƒ…å¢ƒ] æœ‰ä¸Šå‚³åœ–ç‰‡ -> åªçµ¦ user_input + åœ–ç‰‡ base64
                        prompt = f"User input: {user_input}\nHere is the image data in base64:\n{st.session_state.image_base64}..."
                    else:
                        # [æƒ…å¢ƒ] æ²’æœ‰ä¸Šå‚³åœ–ç‰‡ -> ç¶­æŒèˆŠæœ‰è¤‡é›œ JSON é‚è¼¯
                        if st.session_state.uploaded_file_path is not None:
                            try:
                                df_temp = pd.read_csv(st.session_state.uploaded_file_path)
                                csv_columns = ", ".join(df_temp.columns)
                            except Exception as e:
                                csv_columns = "ç„¡æ³•è®€å–æ¬„ä½"
                                if st.session_state.debug_mode:
                                    st.error(f"Error reading columns: {e}")
                                debug_log(f"[DEBUG] Error reading columns: {e}")
                        else:
                            csv_columns = "ç„¡ä¸Šå‚³æª”æ¡ˆ"

                        prompt = f"""Please respond with a JSON object in the format:
{{
    "content": "é€™æ˜¯æˆ‘çš„è§€å¯Ÿï¼š{{{{åˆ†æå…§å®¹}}}}",
    "code": "import pandas as pd\\nimport streamlit as st\\nimport matplotlib.pyplot as plt\\n# è®€å– CSV æª”æ¡ˆ (è«‹ç›´æ¥ä½¿ç”¨ st.session_state.uploaded_file_path è®Šæ•¸)\\ndata = pd.read_csv(st.session_state.uploaded_file_path)\\n\\n# åœ¨é€™è£¡åŠ å…¥ä½ è¦çš„ç¹ªåœ–æˆ–åˆ†æé‚è¼¯\\n\\n# ä¾‹å¦‚ä½¿ç”¨ st.pyplot() ä¾†é¡¯ç¤ºåœ–è¡¨:\\n# fig, ax = plt.subplots()\\n# ax.scatter(data['colA'], data['colB'])\\n# st.pyplot(fig)\\n"
}}
Important:
1) Must use st.session_state.uploaded_file_path as the CSV path (instead of a hardcoded path)
2) Must use st.pyplot() to display any matplotlib figure
3) Return only valid JSON (escape any special characters if needed)

Based on the request: {user_input}.
Available columns: {csv_columns}.
"""

                        if csv_columns == "ç„¡ä¸Šå‚³æª”æ¡ˆ":
                            prompt = f"è«‹å…¨éƒ¨ä»¥ç¹é«”ä¸­æ–‡å›ç­”æ­¤å•é¡Œï¼š{user_input}"

                    debug_log(f"DEBUG: Prompt used => {prompt}")

                    raw_response = st.session_state.conversation.run(prompt)
                    if st.session_state.debug_mode:
                        st.write("Model raw response:", raw_response)
                    debug_log(f"[DEBUG] Model raw response => {raw_response}")

                    # å˜—è©¦æ“·å– JSON
                    json_str = extract_json_block(raw_response)
                    try:
                        response_json = json.loads(json_str)
                    except Exception as e:
                        debug_log(f"json.loads parsing error: {e}")
                        debug_error(f"json.loads parsing error: {e}")
                        response_json = {"content": json_str, "code": ""}

                    content = response_json.get("content", "é€™æ˜¯æˆ‘çš„åˆ†æï¼š")
                    st.session_state.messages.append({"role": "assistant", "content": content})
                    with st.chat_message("assistant"):
                        st.write(content)

                    code = response_json.get("code", "")
                    if code:
                        st.session_state.messages.append({"role": "assistant", "code": code})
                        with st.chat_message("assistant"):
                            st.code(code, language="python")
                        st.session_state.ace_code = code

                    # --- è‹¥å‹¾é¸æ·±åº¦åˆ†ææ¨¡å¼ & æœ‰ç¨‹å¼ç¢¼ -> åŸ·è¡Œç¨‹å¼ã€äºŒæ¬¡è§£æåœ–è¡¨ ---
                    if st.session_state.deep_analysis_mode and code:
                        st.write("### [æ·±åº¦åˆ†æ] è‡ªå‹•åŸ·è¡Œç”¢ç”Ÿçš„ç¨‹å¼ç¢¼ä¸¦å°‡åœ–è¡¨é€è‡³ GPT-4o è§£æ...")

                        global_vars = {
                            "uploaded_file_path": st.session_state.uploaded_file_path,
                            "uploaded_image_path": st.session_state.uploaded_image_path,
                        }
                        exec_result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                        st.write("#### Execution Result")
                        st.text(exec_result)

                        fig = plt.gcf()
                        buf = io.BytesIO()
                        fig.savefig(buf, format="png")
                        buf.seek(0)
                        chart_base64 = base64.b64encode(buf.read()).decode("utf-8")
                        st.session_state.deep_analysis_image = chart_base64

                        # åšç¬¬äºŒéšæ®µå‘¼å«: Deep Analysis
                        if api_key:
                            deep_model = ChatOpenAI(
                                model="gpt-4o",
                                temperature=0.5,
                                openai_api_key=api_key
                            )
                            prompt_2 = f"""
é€™æ˜¯ä¸€å¼µæˆ‘å¾å‰›æ‰çš„ç¨‹å¼ç¢¼ä¸­ç”¢ç”Ÿçš„åœ–è¡¨ï¼Œä»¥ä¸‹æ˜¯åœ–è¡¨çš„base64ç·¨ç¢¼ï¼š
{chart_base64[:300]}...

è«‹ä½ ç‚ºæˆ‘é€²è¡Œé€²ä¸€æ­¥çš„åˆ†æï¼Œè§£é‡‹é€™å¼µåœ–è¡¨å¯èƒ½ä»£è¡¨ä»€éº¼æ¨£çš„æ•¸æ“šè¶¨å‹¢æˆ–è§€å¯Ÿã€‚
"""
                            debug_log(f"DEBUG: Deep Analysis Prompt => {prompt_2}")
                            second_raw_response = deep_model.call_as_llm(prompt_2)
                            st.session_state.second_response = second_raw_response

                            st.write("#### [æ·±åº¦åˆ†æ] åœ–è¡¨è§£æçµæœ (ç¬¬äºŒæ¬¡å›è¦†) :")
                            st.write(second_raw_response)

                            # æœ€å¾Œç¸½çµ
                            final_model = ChatOpenAI(
                                model="gpt-4o",
                                temperature=0.5,
                                openai_api_key=api_key
                            )
                            prompt_3 = f"""
ç¬¬ä¸€éšæ®µå›è¦†å…§å®¹ï¼š{content}
ç¬¬äºŒéšæ®µåœ–è¡¨è§£æå…§å®¹ï¼š{second_raw_response}

è«‹ä½ å¹«æˆ‘æŠŠä»¥ä¸Šå…©éšæ®µçš„å…§å®¹å¥½å¥½åšä¸€å€‹æ–‡å­—ç¸½çµï¼Œä¸¦æä¾›é¡å¤–çš„å»ºè­°æˆ–è¦‹è§£ã€‚
"""
                            debug_log(f"DEBUG: Final Summary Prompt => {prompt_3}")
                            third_raw_response = final_model.call_as_llm(prompt_3)
                            st.session_state.third_response = third_raw_response

                            st.write("#### [æ·±åº¦åˆ†æ] çµè«– (ç¬¬ä¸‰æ¬¡å›è¦†) :")
                            st.write(third_raw_response)

                            st.write("#### [æ·±åº¦åˆ†æ] åœ–è¡¨ï¼š")
                            img_data = base64.b64decode(st.session_state.deep_analysis_image)
                            st.image(img_data, caption="æ·±åº¦åˆ†æç”¢ç”Ÿçš„åœ–è¡¨", use_column_width=True)

                except Exception as e:
                    if st.session_state.debug_mode:
                        st.error(f"An error occurred: {e}")
                    debug_log(f"[DEBUG] An error occurred: {e}")

    # ---------------
    # 4o_image_handle: åœ¨ main é é¢ä¸­é¡å¤–å±•ç¤ºã€Œstream_messagesã€å€å¡Š
    # ---------------
    st.write("## 4o Streaming Chat å€ (ä½¿ç”¨ openai.ChatCompletion.stream)")
    # é¡¯ç¤º 4o çš„å°è©± messages
    for idx, msg in enumerate(st.session_state.stream_messages):
        role = msg["role"]
        contents = msg["content"]
        with st.chat_message(role):
            for c in contents:
                if c["type"] == "text":
                    st.write(c.get("text", ""))
                elif c["type"] == "image_url":
                    st.image(c["image_url"].get("url", ""), caption=f"Image in message {idx}")

    # 4o: ç”¨æˆ¶è¼¸å…¥
    user_input_4o = st.chat_input("4o: Hi! Ask me anything (Streaming approach)...")
    if user_input_4o:
        st.session_state.stream_messages.append({
            "role": "user",
            "content": [{"type": "text", "text": user_input_4o}]
        })
        with st.chat_message("user"):
            st.write(user_input_4o)

        if not api_key:
            st.warning("å°šæœªå¡«å…¥ API Keyï¼Œç„¡æ³•ä½¿ç”¨ 4o ä¸²æµåŠŸèƒ½ã€‚")
        else:
            # ä¸²æµå›æ‡‰
            with st.chat_message("assistant"):
                # å»ºç«‹ä¸€å€‹ç©ºçš„å®¹å™¨ï¼Œé€è¡Œå¯«å…¥ä¸²æµçµæœ
                stream_placeholder = st.empty()
                full_response = ""

                # æº–å‚™ openai çš„ messages
                # è½‰ç‚º openai.ChatCompletion.create() èƒ½ç†è§£çš„æ ¼å¼
                openai_messages = []
                for m in st.session_state.stream_messages:
                    # 4o_image_handle è£¡çš„ msg["content"] å¯èƒ½æ˜¯å¤šç­† text / image
                    # openai éœ€è¦ "role", "content" (éƒ½æ˜¯ text)
                    # é€™è£¡ç°¡åŒ–åšæ³•ï¼šå°‡å¤šå€‹ content åªåˆæˆä¸€å€‹ string
                    msg_role = m["role"]
                    msg_text = []
                    for cobj in m["content"]:
                        if cobj["type"] == "text":
                            msg_text.append(cobj["text"])
                        elif cobj["type"] == "image_url":
                            # ç›´æ¥å°‡ base64 ç•¶æˆæ–‡å­—æè¿°
                            # ï¼ˆçœŸå¯¦æ‡‰ç”¨ä¸­å¯æ•´åˆVision APIæˆ–ç‰¹æ®Šè™•ç†ï¼‰
                            msg_text.append(f"[image_url: {cobj['image_url']['url']}]")
                    combined_text = "\n".join(msg_text)
                    openai_messages.append({"role": msg_role, "content": combined_text})

                for chunk_text in stream_llm_response(openai_messages, model="gpt-4o", temperature=0.3):
                    full_response += chunk_text
                    stream_placeholder.markdown(full_response)

                # å°‡å®Œæ•´å›æ‡‰å­˜å› session
                st.session_state.stream_messages.append({
                    "role": "assistant",
                    "content": [{"type": "text", "text": full_response}]
                })

    # ----------------
    # (b_v2) åœ¨ä¸»é«”æœ€å¾Œï¼šé¡¯ç¤ºã€ŒPersistent Code Editorã€ä½ç½®
    # ----------------
    from streamlit_ace import st_ace  # b_v2 åŸæœ¬å°±æœ‰
    debug_log(f"DEBUG: editor_location = {st.session_state.editor_location}")
    debug_log(f"DEBUG: final st.session_state.uploaded_file_path = {st.session_state.uploaded_file_path}")
    debug_log(f"DEBUG: final st.session_state.uploaded_image_path = {st.session_state.uploaded_image_path}")

    if st.session_state.editor_location == "Main":
        with st.expander("ğŸ–‹ï¸ Persistent Code Editor (Main)", expanded=False):
            edited_code = st_ace(
                value=st.session_state.ace_code,
                language="python",
                theme="monokai",
                height=300,
                key="persistent_editor_main"
            )
            if edited_code != st.session_state.ace_code:
                st.session_state.ace_code = edited_code

            if st.button("â–¶ï¸ Execute Code", key="execute_code_main"):
                global_vars = {
                    "uploaded_file_path": st.session_state.uploaded_file_path,
                    "uploaded_image_path": st.session_state.uploaded_image_path,
                }
                debug_log(f"DEBUG: executing code with uploaded_file_path = {st.session_state.uploaded_file_path}")
                debug_log(f"DEBUG: executing code with uploaded_image_path = {st.session_state.uploaded_image_path}")

                result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                st.write("### Execution Result")
                st.text(result)
    else:
        with st.sidebar.expander("ğŸ–‹ï¸ Persistent Code Editor (Sidebar)", expanded=False):
            edited_code = st_ace(
                value=st.session_state.ace_code,
                language="python",
                theme="monokai",
                height=300,
                key="persistent_editor_sidebar"
            )
            if edited_code != st.session_state.ace_code:
                st.session_state.ace_code = edited_code

            if st.button("â–¶ï¸ Execute Code", key="execute_code_sidebar"):
                global_vars = {
                    "uploaded_file_path": st.session_state.uploaded_file_path,
                    "uploaded_image_path": st.session_state.uploaded_image_path,
                }
                debug_log(f"DEBUG: executing code with uploaded_file_path = {st.session_state.uploaded_file_path}")
                debug_log(f"DEBUG: executing code with uploaded_image_path = {st.session_state.uploaded_image_path}")

                result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                st.write("### Execution Result")
                st.text(result)


# -------------------------------------------
# åŸ·è¡Œå…¥å£
# -------------------------------------------
if __name__ == "__main__":
    main()
