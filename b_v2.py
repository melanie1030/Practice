import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import json
import traceback
import re
import os
import dotenv
import base64
import io
from openai import OpenAI  # è‡ªå®šç¾©çš„ OpenAI é¡åˆ¥
from PIL import Image
from streamlit_ace import st_ace
import openai  # å¼•å…¥ openai æ¨¡çµ„ä»¥ä¾›å…§éƒ¨ä½¿ç”¨

# --- å®šç¾© OpenAI é¡åˆ¥ ---
class OpenAI:
    def __init__(self, api_key):
        openai.api_key = api_key

    class chat:
        class completions:
            @staticmethod
            def create(model, messages, temperature, max_tokens, stream):
                return openai.ChatCompletion.create(
                    model=model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    stream=stream
                )

    # æ·»åŠ  error å±¬æ€§ä»¥ä¾¿æ•æ‰ç•°å¸¸
    class error:
        RateLimitError = openai.error.RateLimitError
        OpenAIError = openai.error.OpenAIError

# --- åˆå§‹åŒ–èˆ‡è¨­ç½® ---
dotenv.load_dotenv()

UPLOAD_DIR = "uploaded_files"

OPENAI_MODELS = [
    "gpt-4-turbo",  # ä½¿ç”¨æ›´ç©©å®šçš„æ¨¡å‹
    "gpt-3.5-turbo-16k",
    "gpt-4",
    "gpt-4-32k",
    "gpt-4o"
]

MAX_MESSAGES = 10  # é™åˆ¶è¨Šæ¯æ­·å²

def debug_log(msg):
    if st.session_state.get("debug_mode", False):
        st.write(f"**DEBUG LOG:** {msg}")
        print(msg)

def debug_error(msg):
    if st.session_state.get("debug_mode", False):
        st.error(f"**DEBUG ERROR:** {msg}")
        print(msg)

def save_uploaded_file(uploaded_file):
    if not os.path.exists(UPLOAD_DIR):
        os.makedirs(UPLOAD_DIR)
    file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)

    debug_log(f"Saving file to {file_path}")
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    debug_log(f"Files in {UPLOAD_DIR}: {os.listdir(UPLOAD_DIR)}")
    return file_path

def load_image_base64(image, max_size=(800, 800)):
    """Load image, resize if necessary, and convert to base64."""
    try:
        # é‡æ–°èª¿æ•´åœ–ç‰‡å¤§å°ä»¥æ¸›å°‘å¤§å°
        image.thumbnail(max_size, Image.LANCZOS)
        
        buffered = io.BytesIO()
        image.save(buffered, format="PNG")
        img_bytes = buffered.getvalue()
        img_base64 = base64.b64encode(img_bytes).decode("utf-8")
        debug_log("Image has been resized and converted to base64.")
        debug_log(f"Image base64 (first 100 chars): {img_base64[:100]}...")
        return img_base64
    except Exception as e:
        debug_error(f"Error converting image to base64: {e}")
        return ""

def append_message(role, content):
    """Append a message and ensure the total number of messages does not exceed MAX_MESSAGES."""
    st.session_state.messages.append({"role": role, "content": content})
    if len(st.session_state.messages) > MAX_MESSAGES:
        # ç§»é™¤æœ€èˆŠçš„è¨Šæ¯ï¼ˆé™¤äº† system promptï¼‰
        # å‡è¨­ system prompt æ˜¯ç¬¬ä¸€æ¢è¨Šæ¯
        st.session_state.messages = [st.session_state.messages[0]] + st.session_state.messages[-(MAX_MESSAGES-1):]
        debug_log("Message history trimmed to maintain token limits.")

def add_user_image(image):
    """Add an image message to the session state."""
    img_base64 = load_image_base64(image)
    if img_base64:
        image_message = f"Here is the image you uploaded:\n![Uploaded Image](data:image/png;base64,{img_base64})"
        append_message("user", image_message)
        st.success("åœ–åƒå·²ä¸Šå‚³!")
    else:
        debug_error("Failed to convert image to base64.")

def execute_code(code, global_vars=None):
    try:
        exec_globals = global_vars if global_vars else {}
        debug_log("Ready to execute the following code:")
        if st.session_state.get("debug_mode", False):
            st.code(code, language="python")

        debug_log(f"Executing code with global_vars: {list(exec_globals.keys())}")
        exec(code, exec_globals)
        output = exec_globals.get("output", "(No output returned)")
        debug_log(f"Execution output: {output}")
        return f"Code executed successfully. Output: {output}"
    except Exception as e:
        error_msg = f"Error executing code:\n{traceback.format_exc()}"
        debug_log(f"Execution error: {error_msg}")
        if st.session_state.get("debug_mode", False):
            return error_msg
        else:
            return "Error executing code (hidden in non-debug mode)."

def extract_json_block(response: str) -> str:
    pattern = r'```(?:json)?\s*(.*?)\s*```'
    match = re.search(pattern, response, re.DOTALL)
    if match:
        json_str = match.group(1).strip()
        debug_log(f"Extracted JSON block: {json_str}")
        return json_str
    else:
        debug_log("No JSON block found in response.")
        return response.strip()

def stream_llm_response(client, model_params):
    """Stream responses from the LLM model."""
    try:
        response = client.chat.completions.create(
            model=model_params.get("model", "gpt-4-turbo"),
            messages=st.session_state.messages,
            temperature=model_params.get("temperature", 0.3),
            max_tokens=model_params.get("max_tokens", 4096),
            stream=True
        )
        response_content = ""
        assistant_placeholder = st.empty()  # Create a placeholder for assistant's response

        for chunk in response:
            chunk_text = chunk.choices[0].delta.get('content', '')
            if chunk_text:
                response_content += chunk_text
                # Update the assistant's response in the placeholder
                assistant_placeholder.markdown(response_content)
                debug_log(f"Received chunk: {chunk_text[:100]}...")
        return response_content
    except OpenAI.error.RateLimitError as e:
        debug_error(f"Rate limit exceeded: {e}")
        st.error("Rate limit exceeded. Please try again later.")
        return ""
    except OpenAI.error.OpenAIError as e:
        debug_error(f"OpenAI error: {e}")
        st.error(f"An OpenAI error occurred: {e}")
        return ""
    except Exception as e:
        debug_error(f"Error streaming response: {e}")
        st.error(f"An error occurred while streaming the response: {e}")
        return ""

def main():
    st.set_page_config(page_title="Chatbot + Data Analysis", page_icon="ğŸ¤–", layout="wide")
    st.title("ğŸ¤– Chatbot + ğŸ“Š Data Analysis + ğŸ§  Memory + ğŸ–‹ï¸ Canvas (With Debug & Deep Analysis)")

    # Initialize session state variables
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "ace_code" not in st.session_state:
        st.session_state.ace_code = ""
    if "editor_location" not in st.session_state:
        st.session_state.editor_location = "Main"
    if "uploaded_file_path" not in st.session_state:
        st.session_state.uploaded_file_path = None
    if "uploaded_image_path" not in st.session_state:
        st.session_state.uploaded_image_path = None
    if "image_base64" not in st.session_state:
        st.session_state.image_base64 = None
    if "debug_mode" not in st.session_state:
        st.session_state.debug_mode = False
    if "deep_analysis_mode" not in st.session_state:
        st.session_state.deep_analysis_mode = False
    if "second_response" not in st.session_state:
        st.session_state.second_response = ""
    if "third_response" not in st.session_state:
        st.session_state.third_response = ""
    if "deep_analysis_image" not in st.session_state:
        st.session_state.deep_analysis_image = None

    with st.sidebar:
        st.subheader("ğŸ”’ Enter Your API Key")
        api_key = st.text_input("OpenAI API Key", type="password")

        selected_model = st.selectbox("é¸æ“‡æ¨¡å‹:", OPENAI_MODELS, index=0)

        st.session_state.debug_mode = st.checkbox("Debug Mode", value=False)
        st.session_state.deep_analysis_mode = st.checkbox("æ·±åº¦åˆ†ææ¨¡å¼", value=False)

        if "memory" not in st.session_state:
            st.session_state.memory = []

        if "conversation_initialized" not in st.session_state:
            if api_key:
                # Initialize OpenAI client
                client = OpenAI(api_key)
                st.session_state.conversation_initialized = True
                st.session_state.messages = []  # Initialize with empty message history
                debug_log("Conversation initialized with empty message history.")
            else:
                st.warning("â¬…ï¸ è«‹è¼¸å…¥ API Key ä»¥åˆå§‹åŒ–èŠå¤©æ©Ÿå™¨äººã€‚")

        if st.session_state.debug_mode:
            debug_log(f"Currently using model => {selected_model}")

        if st.button("ğŸ—‘ï¸ Clear Memory"):
            st.session_state.memory = []
            st.session_state.messages = []
            st.session_state.ace_code = ""
            st.session_state.uploaded_file_path = None
            st.session_state.uploaded_image_path = None
            st.session_state.image_base64 = None
            st.session_state.deep_analysis_mode = False
            st.session_state.second_response = ""
            st.session_state.third_response = ""
            st.session_state.deep_analysis_image = None
            st.success("Memory cleared!")
            debug_log("Memory has been cleared.")

        st.subheader("ğŸ§  Memory State")
        if st.session_state.messages:
            memory_content = "\n".join([f"{msg['role']}: {msg['content']}" for msg in st.session_state.messages])
            st.text_area("Current Memory", value=memory_content, height=200)
            debug_log(f"Current memory content: {memory_content}")
        else:
            st.text_area("Current Memory", value="No messages yet.", height=200)
            debug_log("No messages in memory.")

        # --- CSV ä¸Šå‚³ ---
        st.subheader("ğŸ“‚ Upload a CSV File")
        uploaded_file = st.file_uploader("Choose a CSV file:", type=["csv"])
        csv_data = None
        if uploaded_file:
            st.session_state.uploaded_file_path = save_uploaded_file(uploaded_file)
            debug_log(f"Uploaded file path: {st.session_state.uploaded_file_path}")
            try:
                csv_data = pd.read_csv(st.session_state.uploaded_file_path)
                st.write("### Data Preview")
                st.dataframe(csv_data)
                debug_log(f"CSV Data Columns: {list(csv_data.columns)}")
            except Exception as e:
                if st.session_state.debug_mode:
                    st.error(f"Error reading CSV: {e}")
                debug_log(f"Error reading CSV: {e}")

        # --- åœ–ç‰‡ä¸Šå‚³ ---
        st.subheader("ğŸ–¼ï¸ Upload an Image")
        uploaded_image = st.file_uploader("é¸æ“‡ä¸€å¼µåœ–ç‰‡:", type=["png", "jpg", "jpeg"])
        if uploaded_image:
            add_user_image(Image.open(uploaded_image))

        st.subheader("Editor Location")
        location = st.radio(
            "Choose where to display the editor:",
            ["Main", "Sidebar"],
            index=0 if st.session_state.editor_location == "Main" else 1
        )
        st.session_state.editor_location = location
        debug_log(f"Editor location set to: {st.session_state.editor_location}")

    # --- é¡¯ç¤ºæ­·å²è¨Šæ¯ ---
    for idx, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            if isinstance(message["content"], dict) and "code" in message["content"]:
                st.code(message["content"]["code"], language="python")
                debug_log(f"Displaying code from {message['role']}: {message['content']['code']}")
            else:
                st.write(message["content"])
                debug_log(f"Displaying message {idx} from {message['role']}: {message['content']}")

    # --- ç”¨æˆ¶è¼¸å…¥ ---
    user_input = st.chat_input("Hi! Ask me anything...")
    if user_input:
        append_message("user", user_input)
        with st.chat_message("user"):
            st.write(user_input)
            debug_log(f"User input added to messages: {user_input}")

        with st.spinner("Thinking..."):
            try:
                # Initialize OpenAI client if not already done
                if api_key:
                    client = OpenAI(api_key)
                else:
                    raise ValueError("OpenAI API Key is not provided.")

                debug_log(f"Uploaded file path: {st.session_state.uploaded_file_path}")
                debug_log(f"Uploaded image path: {st.session_state.uploaded_image_path}")

                # --- ç¢ºä¿ system prompt åƒ…æ·»åŠ ä¸€æ¬¡ ---
                if not any(msg["role"] == "system" for msg in st.session_state.messages):
                    system_prompt = "ä½ æ˜¯ä¸€å€‹å”åŠ©é€²è¡Œæ•¸æ“šåˆ†æçš„åŠ©æ‰‹ã€‚"
                    append_message("system", system_prompt)
                    debug_log("System prompt added to messages.")

                # --- æ±ºå®šä½¿ç”¨å“ªç¨® prompt ---
                if st.session_state.uploaded_image_path is not None and st.session_state.image_base64:
                    # åœ–ç‰‡å·²ä¸Šå‚³ï¼Œåœ–ç‰‡æ•¸æ“šå·²ä½œç‚ºå–®ç¨çš„è¨Šæ¯æ·»åŠ 
                    prompt = user_input  # ç›´æ¥ä½¿ç”¨ç”¨æˆ¶è¼¸å…¥
                    debug_log("User input with image data already appended.")
                else:
                    # æ²’æœ‰åœ–ç‰‡ä¸Šå‚³ï¼Œä½¿ç”¨è¤‡é›œçš„ JSON é‚è¼¯
                    if st.session_state.uploaded_file_path is not None:
                        try:
                            df_temp = pd.read_csv(st.session_state.uploaded_file_path)
                            csv_columns = ", ".join(df_temp.columns)
                            debug_log(f"CSV columns: {csv_columns}")
                        except Exception as e:
                            csv_columns = "ç„¡æ³•è®€å–æ¬„ä½"
                            if st.session_state.debug_mode:
                                st.error(f"Error reading columns: {e}")
                            debug_log(f"Error reading columns: {e}")
                    else:
                        csv_columns = "ç„¡ä¸Šå‚³æª”æ¡ˆ"
                        debug_log("No CSV file uploaded.")

                    if st.session_state.uploaded_file_path is not None and csv_columns != "ç„¡ä¸Šå‚³æª”æ¡ˆ":
                        prompt = f"""Please respond with a JSON object in the format:
{{
    "content": "é€™æ˜¯æˆ‘çš„è§€å¯Ÿï¼š{{{{åˆ†æå…§å®¹}}}}",
    "code": "import pandas as pd\\nimport streamlit as st\\nimport matplotlib.pyplot as plt\\n# è®€å– CSV æª”æ¡ˆ (è«‹ç›´æ¥ä½¿ç”¨ st.session_state.uploaded_file_path è®Šæ•¸)\\ndata = pd.read_csv(st.session_state.uploaded_file_path)\\n\\n# åœ¨é€™è£¡åŠ å…¥ä½ è¦çš„ç¹ªåœ–æˆ–åˆ†æé‚è¼¯\\n\\n# ä¾‹å¦‚ä½¿ç”¨ st.pyplot() ä¾†é¡¯ç¤ºåœ–è¡¨:\\n# fig, ax = plt.subplots()\\n# ax.scatter(data['colA'], data['colB'])\\n# st.pyplot(fig)\\n"
}}
Important:
1) Must use st.session_state.uploaded_file_path as the CSV path (instead of a hardcoded path)
2) Must use st.pyplot() to display any matplotlib figure
3) Return only valid JSON (escape any special characters if needed)

Based on the request: {user_input}.
Available columns: {csv_columns}.
"""
                        debug_log("Prompt constructed for CSV input with JSON response.")
                        append_message("system", prompt)
                        debug_log("System prompt appended to messages.")
                    else:
                        prompt = f"è«‹å…¨éƒ¨ä»¥ç¹é«”ä¸­æ–‡å›ç­”æ­¤å•é¡Œï¼š{user_input}"
                        debug_log("Prompt constructed for plain text input.")
                        append_message("system", prompt)
                        debug_log("Plain text system prompt appended to messages.")

                # Make the API request and stream the response
                model_params = {
                    "model": selected_model,
                    "temperature": 0.5,
                    "max_tokens": 4096
                }
                response_content = stream_llm_response(client, model_params)
                debug_log(f"Full assistant response: {response_content}")

                if response_content:
                    # After streaming is done, append assistant message
                    append_message("assistant", response_content)
                    with st.chat_message("assistant"):
                        st.write(response_content)
                        debug_log(f"Assistant response added to messages: {response_content}")

                    # Extract JSON and code
                    json_str = extract_json_block(response_content)
                    try:
                        response_json = json.loads(json_str)
                        debug_log("JSON parsing successful.")
                    except Exception as e:
                        debug_log(f"json.loads parsing error: {e}")
                        debug_error(f"json.loads parsing error: {e}")
                        response_json = {"content": json_str, "code": ""}
                        debug_log("Fallback to raw response for content.")

                    content = response_json.get("content", "é€™æ˜¯æˆ‘çš„åˆ†æï¼š")
                    append_message("assistant", content)
                    with st.chat_message("assistant"):
                        st.write(content)
                        debug_log(f"Content from JSON appended to messages: {content}")

                    code = response_json.get("code", "")
                    if code:
                        # å°‡ä»£ç¢¼ä½œç‚ºç¨ç«‹çš„è¨Šæ¯æ·»åŠ 
                        append_message("assistant", {"code": code})
                        with st.chat_message("assistant"):
                            st.code(code, language="python")
                            debug_log(f"Code from JSON appended to messages: {code}")
                        st.session_state.ace_code = code
                        debug_log("ace_code updated with new code.")

                    # --- è‹¥å‹¾é¸æ·±åº¦åˆ†ææ¨¡å¼ & æœ‰ç¨‹å¼ç¢¼ -> åŸ·è¡Œç¨‹å¼ã€äºŒæ¬¡è§£æåœ–è¡¨ ---
                    if st.session_state.deep_analysis_mode and code:
                        st.write("### [æ·±åº¦åˆ†æ] è‡ªå‹•åŸ·è¡Œç”¢ç”Ÿçš„ç¨‹å¼ç¢¼ä¸¦å°‡åœ–è¡¨é€è‡³ GPT-4o è§£æ...")
                        debug_log("Deep analysis mode activated.")

                        global_vars = {
                            "uploaded_file_path": st.session_state.uploaded_file_path,
                            "uploaded_image_path": st.session_state.uploaded_image_path,
                        }
                        exec_result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                        st.write("#### Execution Result")
                        st.text(exec_result)
                        debug_log(f"Execution result: {exec_result}")

                        fig = plt.gcf()
                        buf = io.BytesIO()
                        fig.savefig(buf, format="png")
                        buf.seek(0)
                        chart_base64 = base64.b64encode(buf.read()).decode("utf-8")
                        st.session_state.deep_analysis_image = chart_base64
                        debug_log("Chart has been converted to base64.")

                        # Prepare deep analysis prompt
                        prompt_2 = f"""
é€™æ˜¯ä¸€å¼µæˆ‘å¾å‰›æ‰çš„ç¨‹å¼ç¢¼ä¸­ç”¢ç”Ÿçš„åœ–è¡¨ï¼Œä»¥ä¸‹æ˜¯åœ–è¡¨çš„base64ç·¨ç¢¼ï¼š
![image](data:image/png;base64,{chart_base64})

è«‹ä½ ç‚ºæˆ‘é€²è¡Œé€²ä¸€æ­¥çš„åˆ†æï¼Œè§£é‡‹é€™å¼µåœ–è¡¨å¯èƒ½ä»£è¡¨ä»€éº¼æ¨£çš„æ•¸æ“šè¶¨å‹¢æˆ–è§€å¯Ÿã€‚
"""
                        debug_log(f"Deep Analysis Prompt: {prompt_2}")

                        # Append prompt_2 to messages
                        append_message("user", prompt_2)
                        debug_log("Deep analysis prompt appended to messages.")

                        # Make the API request for deep analysis
                        second_raw_response = stream_llm_response(client, model_params)
                        debug_log(f"Deep analysis response: {second_raw_response}")

                        if second_raw_response:
                            # Append assistant response
                            append_message("assistant", second_raw_response)
                            st.session_state.second_response = second_raw_response
                            with st.chat_message("assistant"):
                                st.write(second_raw_response)
                                debug_log(f"Deep analysis response added to messages: {second_raw_response}")

                            # Prepare final summary prompt
                            prompt_3 = f"""
ç¬¬ä¸€éšæ®µå›è¦†å…§å®¹ï¼š{content}
ç¬¬äºŒéšæ®µåœ–è¡¨è§£æå…§å®¹ï¼š{second_raw_response}

è«‹ä½ å¹«æˆ‘æŠŠä»¥ä¸Šå…©éšæ®µçš„å…§å®¹å¥½å¥½åšä¸€å€‹æ–‡å­—ç¸½çµï¼Œä¸¦æä¾›é¡å¤–çš„å»ºè­°æˆ–è¦‹è§£ã€‚
"""
                            debug_log(f"Final Summary Prompt: {prompt_3}")

                            # Append prompt_3 to messages
                            append_message("user", prompt_3)
                            debug_log("Final summary prompt appended to messages.")

                            # Make the API request for final summary
                            third_raw_response = stream_llm_response(client, model_params)
                            debug_log(f"Final summary response: {third_raw_response}")

                            if third_raw_response:
                                # Append assistant response
                                append_message("assistant", third_raw_response)
                                st.session_state.third_response = third_raw_response
                                with st.chat_message("assistant"):
                                    st.write(third_raw_response)
                                    debug_log(f"Final summary response added to messages: {third_raw_response}")

                                # Display the chart
                                st.write("#### [æ·±åº¦åˆ†æ] åœ–è¡¨ï¼š")
                                try:
                                    img_data = base64.b64decode(st.session_state.deep_analysis_image)
                                    st.image(img_data, caption="æ·±åº¦åˆ†æç”¢ç”Ÿçš„åœ–è¡¨", use_column_width=True)
                                    debug_log("Deep analysis chart displayed.")
                                except Exception as e:
                                    if st.session_state.debug_mode:
                                        st.error(f"Error displaying chart: {e}")
                                    debug_log(f"Error displaying chart: {e}")

            except Exception as e:
                if st.session_state.debug_mode:
                    st.error(f"An error occurred: {e}")
                debug_log(f"An error occurred: {e}")

    # --- Persistent Code Editor ---
    if "ace_code" not in st.session_state:
        st.session_state.ace_code = ""

    if st.session_state.editor_location == "Main":
        with st.expander("ğŸ–‹ï¸ Persistent Code Editor (Main)", expanded=False):
            edited_code = st_ace(
                value=st.session_state.ace_code,
                language="python",
                theme="monokai",
                height=300,
                key="persistent_editor_main"
            )
            if edited_code != st.session_state.ace_code:
                st.session_state.ace_code = edited_code
                debug_log("ace_code updated from main editor.")

            if st.button("â–¶ï¸ Execute Code", key="execute_code_main"):
                global_vars = {
                    "uploaded_file_path": st.session_state.uploaded_file_path,
                    "uploaded_image_path": st.session_state.uploaded_image_path,
                }
                debug_log(f"Executing code with uploaded_file_path = {st.session_state.uploaded_file_path}")
                debug_log(f"Executing code with uploaded_image_path = {st.session_state.uploaded_image_path}")

                result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                st.write("### Execution Result")
                st.text(result)
                debug_log(f"Code execution result: {result}")

    else:
        with st.sidebar.expander("ğŸ–‹ï¸ Persistent Code Editor (Sidebar)", expanded=False):
            edited_code = st_ace(
                value=st.session_state.ace_code,
                language="python",
                theme="monokai",
                height=300,
                key="persistent_editor_sidebar"
            )
            if edited_code != st.session_state.ace_code:
                st.session_state.ace_code = edited_code
                debug_log("ace_code updated from sidebar editor.")

            if st.button("â–¶ï¸ Execute Code", key="execute_code_sidebar"):
                global_vars = {
                    "uploaded_file_path": st.session_state.uploaded_file_path,
                    "uploaded_image_path": st.session_state.uploaded_image_path,
                }
                debug_log(f"Executing code with uploaded_file_path = {st.session_state.uploaded_file_path}")
                debug_log(f"Executing code with uploaded_image_path = {st.session_state.uploaded_image_path}")

                result = execute_code(st.session_state.ace_code, global_vars=global_vars)
                st.write("### Execution Result")
                st.text(result)
                debug_log(f"Code execution result: {result}")

if __name__ == "__main__":
    main()
