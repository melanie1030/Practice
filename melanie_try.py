import streamlit as st
import os
import openai
from langchain_openai import ChatOpenAI
import httpx
import traceback

# --- æ¸¬è©¦ä¸€ï¼šåŸç”Ÿ OpenAI å‡½å¼åº« ---
def test_native_openai(api_key):
    st.info("--- é–‹å§‹æ¸¬è©¦ä¸€ï¼šåŸç”Ÿ OpenAI ---")
    if not api_key:
        st.error("API Key ç‚ºç©ºï¼Œç„¡æ³•æ¸¬è©¦ã€‚")
        return

    # ä½¿ç”¨æˆ‘å€‘ä¹‹å‰æœ€ç©©å¥çš„ä»£ç†è™•ç†é‚è¼¯
    PROXY_ENV_VARS = ["http_proxy", "https_proxy", "all_proxy", "HTTP_PROXY", "HTTPS_PROXY", "ALL_PROXY"]
    original_proxies = {key: os.environ.get(key) for key in PROXY_ENV_VARS if os.environ.get(key)}
    proxy_url_for_httpx = next((p for p in original_proxies.values() if p), None)
    
    for key in original_proxies:
        if key in os.environ: del os.environ[key]
    
    client = None
    try:
        st.write("ç’°å¢ƒè®Šæ•¸å·²æš«æ™‚ç§»é™¤ï¼Œæº–å‚™åˆå§‹åŒ– Client...")
        http_client = httpx.Client(proxies=proxy_url_for_httpx) if proxy_url_for_httpx else None
        
        # ç›´æ¥åˆå§‹åŒ–åŸºç¤ OpenAI Client
        client = openai.OpenAI(api_key=api_key, http_client=http_client)
        
        st.write("åŸç”Ÿ OpenAI Client åˆå§‹åŒ–æˆåŠŸï¼æ­£åœ¨å˜—è©¦ç™¼é€è«‹æ±‚...")
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": "Say this is a test!"}],
            max_tokens=5
        )
        
        st.success(f"âœ… **æ¸¬è©¦ä¸€æˆåŠŸï¼** æ¨¡å‹å›æ‡‰: {response.choices[0].message.content}")

    except Exception as e:
        st.error(f"âŒ **æ¸¬è©¦ä¸€å¤±æ•—ï¼**")
        st.code(f"éŒ¯èª¤é¡å‹: {type(e)}\néŒ¯èª¤è¨Šæ¯: {e}")
        st.text("éŒ¯èª¤è¿½è¹¤:")
        st.code(traceback.format_exc())
    finally:
        # æ¢å¾©ç’°å¢ƒè®Šæ•¸
        for key, value in original_proxies.items():
            os.environ[key] = value
        st.info("ç’°å¢ƒè®Šæ•¸å·²æ¢å¾©ã€‚")


# --- æ¸¬è©¦äºŒï¼šLangChain çš„ ChatOpenAI ---
def test_langchain_openai(api_key):
    st.info("--- é–‹å§‹æ¸¬è©¦äºŒï¼šLangChain ChatOpenAI ---")
    if not api_key:
        st.error("API Key ç‚ºç©ºï¼Œç„¡æ³•æ¸¬è©¦ã€‚")
        return

    try:
        st.write("æº–å‚™åˆå§‹åŒ– LangChain çš„ ChatOpenAI...")
        
        # é€™æ˜¯æˆ‘å€‘ä¸€ç›´é‡åˆ°å•é¡Œçš„åœ°æ–¹
        llm = ChatOpenAI(
            temperature=0, 
            model="gpt-4o", 
            api_key=api_key
        )
        
        st.write("LangChain ChatOpenAI åˆå§‹åŒ–æˆåŠŸï¼æ­£åœ¨å˜—è©¦ç™¼é€è«‹æ±‚...")
        
        response = llm.invoke("Say this is a test!")
        
        st.success(f"âœ… **æ¸¬è©¦äºŒæˆåŠŸï¼** æ¨¡å‹å›æ‡‰: {response.content}")

    except Exception as e:
        st.error(f"âŒ **æ¸¬è©¦äºŒå¤±æ•—ï¼**")
        st.code(f"éŒ¯èª¤é¡å‹: {type(e)}\néŒ¯èª¤è¨Šæ¯: {e}")
        st.text("éŒ¯èª¤è¿½è¹¤:")
        st.code(traceback.format_exc())


# --- ä¸»æ‡‰ç”¨ä»‹é¢ ---
def main():
    st.title("ğŸ”´ æœ€çµ‚æ ¹æœ¬åŸå› è¨ºæ–·")
    st.write("é€™å€‹é é¢ç”¨ä¾†éš”é›¢ä¸¦æ‰¾å‡ºå°è‡´ `proxies` éŒ¯èª¤çš„æ ¹æœ¬åŸå› ã€‚")

    api_key = st.text_input(
        "è«‹è¼¸å…¥æ‚¨çš„ OpenAI API Key", 
        type="password", 
        help="æ­¤é‡‘é‘°åƒ…ç”¨æ–¼æœ¬æ¬¡æ¸¬è©¦ï¼Œä¸æœƒè¢«å„²å­˜ã€‚"
    )

    st.divider()

    col1, col2 = st.columns(2)

    with col1:
        if st.button("åŸ·è¡Œæ¸¬è©¦ä¸€ï¼šåŸç”Ÿ OpenAI å‡½å¼åº«", use_container_width=True):
            test_native_openai(api_key)

    with col2:
        if st.button("åŸ·è¡Œæ¸¬è©¦äºŒï¼šLangChain çš„ ChatOpenAI", use_container_width=True, type="primary"):
            test_langchain_openai(api_key)
            
if __name__ == "__main__":
    main()
